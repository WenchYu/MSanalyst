{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee2c360-0514-4a21-8e6c-62665b68b16d",
   "metadata": {},
   "source": [
    "# Import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6d343-4336-4262-87c0-785ad956101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['jupyter']  # Clear the parameters passed to Jupyter\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3bdf5-84a7-441b-939d-ad44fe86c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import sys,os,time,json,functools,argparse,heapq,pickle,ast\n",
    "sys.path.append('../')\n",
    "from my_packages import cheminfo_tools,functions_new,evaluation,peaktools\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "\n",
    "import os,json,ujson,ms_entropy,matchms,json,spectral_entropy,sys,time\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import spectral_entropy as se\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import spectrum_utils.spectrum as sus\n",
    "\n",
    "from spectral_entropy.spectral_entropy import calculate_entropy\n",
    "from spectral_entropy import similarity\n",
    "from matchms.importing import load_from_json, load_from_mgf,load_from_msp, load_from_mzml, load_from_mzxml, load_from_usi\n",
    "from tqdm import tqdm, trange\n",
    "from ms_entropy import FlashEntropySearch,FlashEntropySearchCore\n",
    "from my_packages import functions_new,ms2tools_new,cheminfo_tools,evaluation\n",
    "from rdkit import Chem\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve,auc,confusion_matrix\n",
    "from FPSim2.io import create_db_file\n",
    "from FPSim2 import FPSim2Engine\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matchms import Spectrum\n",
    "from matchms.similarity import ModifiedCosine,NeutralLossesCosine,CosineGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1b85c-1e6e-45f8-8f15-685ec977fbda",
   "metadata": {},
   "source": [
    "# Load library files\n",
    "## EDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4f127-9a62-434e-9cdb-780f445c343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GNPS library file\n",
    "t = time.time() \n",
    "\n",
    "# GNPS_FILE = '../msdb/GNPSLIBRARY_250514/ALL_GNPS_NO_PROPOGATED.mgf'\n",
    "GNPS_CLEAN_FILE = '../msdb/GNPSLIBRARY_250514/ALL_GNPS_cleaned.mgf'\n",
    "# GNPS_DEMO_FILE = '../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-demo.mgf'\n",
    "\n",
    "# GNPS_INFO = list(load_from_mgf(GNPS_FILE))\n",
    "GNPS_CLAEN_INFO = list(load_from_mgf(GNPS_CLEAN_FILE))\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201c9bf-a16a-4482-bab5-5ac8a4a06500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library spectral file\n",
    "t = time.time()\n",
    "\n",
    "# ISMS1_CSV = '../msdb/isdbMS1.csv' # 'id', 'formula', 'exactmass', 'smiles', 'inchi', 'inchikey', 'm+h','m+nh4', 'm+na'\n",
    "# ISMS1_DF = pd.read_csv(ISMS1_CSV,low_memory=False)\n",
    "# EMS1_CSV = '../msdb/edbMS1.csv' # 'id', 'pepmass', 'smiles'\n",
    "# EMS1_DF = pd.read_csv(EMS1_CSV)\n",
    "\n",
    "# Flash search - Load\n",
    "FS_E_LIBRARY = functions_new.json_load('../msdb/FS_edb_info.json')\n",
    "e_search = FlashEntropySearch()\n",
    "FS_E_LIBRARY = e_search.build_index(FS_E_LIBRARY)\n",
    "\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7439fc-526e-4f98-af70-dfa8d6ff027b",
   "metadata": {},
   "source": [
    "## ISDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c086fe-5f8b-4f16-8d90-db66512fdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB energy 10,20,40\n",
    "ISDB_INFO = functions_new.json_load('../msdb/isdb_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f98696-a071-475c-9c0a-d188bfc1c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB energy = 10\n",
    "t = time.time()\n",
    "FS_IS_LIBRARY_e0 = functions_new.json_load('../msdb/FS_isdb_e0.json')\n",
    "is0_search = FlashEntropySearch()\n",
    "FS_IS0_LIBRARY = is0_search.build_index(FS_IS_LIBRARY_e0)\n",
    "\n",
    "# ISDB energy = 20\n",
    "t = time.time()\n",
    "FS_IS_LIBRARY_e1 = functions_new.json_load('../msdb/FS_isdb_e1.json')\n",
    "is1_search = FlashEntropySearch()\n",
    "FS_IS1_LIBRARY = is1_search.build_index(FS_IS_LIBRARY_e1)\n",
    "\n",
    "# ISDB energy = 40\n",
    "t = time.time()\n",
    "FS_IS_LIBRARY_e2 = functions_new.json_load('../msdb/FS_isdb_e2.json')\n",
    "is2_search = FlashEntropySearch()\n",
    "FS_IS2_LIBRARY = is2_search.build_index(FS_IS_LIBRARY_e2)\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e28992-ad50-4230-83c1-27145125365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Selected CCMSids\n",
    "CCMSIDs = np.load('../msdb/data/idlist/H_qtof_non-redundant_CCMSIDs.npy')\n",
    "\n",
    "# Library files\n",
    "GNPS_INFO_FILE = '../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json'\n",
    "GNPS_INFO = functions_new.json_load(GNPS_INFO_FILE)\n",
    "\n",
    "# Tanimoto matrix\n",
    "TANIMOTO_MATRIX_FILE = f'../msdb/data/structural_matrix/tanimoto_similarity_matrix.npy'\n",
    "TANIMOTO_MATRIX = np.load(TANIMOTO_MATRIX_FILE) # Tanimoto similarity matrices\n",
    "IDXtoCCMSID = functions_new.json_load('../msdb/data/idlist/INDEXtoCCMS.json')\n",
    "CCMSIDtoIDX = {value:key for key,value in IDXtoCCMSID.items() }\n",
    "\n",
    "# ALGORITHMs\n",
    "G1,G2,G3,G4 = topology.get_groups()\n",
    "ALGORITHMs = G1 + G2 + G3 + G4 + ['peak_percentage'] \n",
    "ALGORITHM = [a for a in ALGORITHMs if 'modified_' in a][0] # ALGORITHMS\n",
    "\n",
    "# Spectral matrices\n",
    "SPEC_SIM_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy'\n",
    "SPEC_SIM_MATRIX = np.load(SPEC_SIM_MATRIX_FILE)\n",
    "\n",
    "if ALGORITHM == 'neutral_loss':\n",
    "    N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_peak_matrix.npy'  # expect for modified_cosine and neutral_loss\n",
    "elif ALGORITHM == 'modified_cosine':\n",
    "    N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_peak_matrix.npy'\n",
    "else:\n",
    "    N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/cosine_peak_matrix.npy'\n",
    "N_PEAK_MATRIX = np.load(N_PEAK_MATRIX_FILE)\n",
    "\n",
    "# MS1 matchi matrix(1: match, 0: not match)\n",
    "MS1_MATCH_MATRIX = np.load(f'../msdb/data/structural_matrix/MS1match_matrix.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e7187-5e7e-4056-95fb-90e6ee156b40",
   "metadata": {},
   "source": [
    "## Npeak and entropy supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c04d1-b507-4410-a637-dd0975f9c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplement the library with additional information (e.g., entropy, n_peaks, classes)\n",
    "# Param: FS_E_LIBRARY,FS_IS0_LIBRARY,FS_IS1_LIBRARY,FS_IS2_LIBRARY,\n",
    "# Return: LIBRARIES with supplemented information \n",
    "for SPECTRUM in tqdm(FS_E_LIBRARY, total = len(FS_E_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd6bcc-a4cb-4c17-9fdf-21d50eb1a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for SPECTRUM in tqdm(FS_IS0_LIBRARY, total = len(FS_IS0_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    SPECTRUM['peaks'] = PEAKs.tolist()\n",
    "    \n",
    "for SPECTRUM in tqdm(FS_IS1_LIBRARY, total = len(FS_IS1_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    SPECTRUM['peaks'] = PEAKs.tolist()\n",
    "\n",
    "for SPECTRUM in tqdm(FS_IS2_LIBRARY, total = len(FS_IS2_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    SPECTRUM['peaks'] = PEAKs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5fc2a-9bac-4da0-a8f4-691aadd78c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../msdb/FS_isdb_e0.json', \"w\") as f:\n",
    "    json.dump(FS_IS0_LIBRARY, f)\n",
    "\n",
    "with open('../msdb/FS_isdb_e1.json', \"w\") as f:\n",
    "    json.dump(FS_IS1_LIBRARY, f)\n",
    "\n",
    "with open('../msdb/FS_isdb_e2.json', \"w\") as f:\n",
    "    json.dump(FS_IS2_LIBRARY, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16071f8e-bc49-48fb-864b-6ebe49df124b",
   "metadata": {},
   "source": [
    "## Hqtof lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01641e8a-6890-4dac-8755-6c4fc72ca2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GNPS library\n",
    "GNPS_SPECTRA = list(load_from_mgf('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY.mgf'))\n",
    "GNPS_INFO = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b896f-2d8d-4ac1-b7f4-6e1c64783803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2571 \n",
    "# \n",
    "Hqtof_CCMSIDs = list(np.load('../msdb/data/hqtof/idlist/H_qtof_non-redundant_CCMSIDs.npy'))\n",
    "\n",
    "# FS_SPECTRA = []\n",
    "# for SPECTRUM in tqdm(GNPS_SPECTRA,total = len(GNPS_SPECTRA)):\n",
    "#     CCMSID = SPECTRUM.metadata['spectrum_id']\n",
    "#     if CCMSID in Hqtof_CCMSIDs:\n",
    "#         PM = SPECTRUM.metadata['precursor_mz']\n",
    "#         IONMODE = SPECTRUM.metadata['ionmode']\n",
    "#         try:\n",
    "#             SMILE = SPECTRUM.metadata['smiles']\n",
    "#         except:\n",
    "#             SMILE = GNPS_INFO[CCMSID]['CANONSMILES']\n",
    "            \n",
    "#         CHARGE = SPECTRUM.metadata['charge']\n",
    "#         SCLASS = GNPS_INFO[CCMSID]['np_classifier_superclass']\n",
    "        \n",
    "#         peaks = np.column_stack((SPECTRUM.mz,SPECTRUM.intensities))\n",
    "#         # peaks = se.clean_spectrum(peaks, max_mz=PM + 1.6)\n",
    "#         FS_SPECTRA.append({\n",
    "#             \"id\": CCMSID,\n",
    "#             \"precursor_mz\": PM,\n",
    "#             \"peaks\": peaks.tolist(),\n",
    "#             \"smile\": SMILE,\n",
    "#             \"charge\": CHARGE,\n",
    "#             \"ion_mode\":IONMODE,\n",
    "#             'superclass':[SCLASS]\n",
    "#             })\n",
    "\n",
    "# # Save\n",
    "# sorted_list = sorted(FS_SPECTRA, key=lambda x: x['precursor_mz'])\n",
    "# FS_GNPS_LIBRARY_OUTPUT = '../msdb/FS_hqtof.json'\n",
    "# with open(FS_GNPS_LIBRARY_OUTPUT, \"w\") as f:\n",
    "#     json.dump(sorted_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5fc8f-20ac-4777-b5a5-95c89ce5fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "HQTOF = functions_new.json_load('../msdb/FS_hqtof.json')\n",
    "hqtof_search = FlashEntropySearch()\n",
    "FS_SPECTRA = hqtof_search.build_index(HQTOF) # Pre-clean and sorted flash spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8875dab-d3f6-43d5-b7a2-845ad02a73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FS_SPECTRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a78d0-bb54-4ceb-9e73-0756db195f5d",
   "metadata": {},
   "source": [
    "# Kdeplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff2c5e4-a7f1-4e33-9b55-dfa79a0359ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_density(X,Y):\n",
    "    '''\n",
    "    Pre-calculate density for kde plot\n",
    "    '''\n",
    "    kde = gaussian_kde(np.vstack([X, Y]), bw_method='silverman')\n",
    "    x_grid, y_grid = np.mgrid[x.min():x.max():100j, y.min():y.max():100j]\n",
    "    positions = np.vstack([x_grid.ravel(), y_grid.ravel()])\n",
    "    density = kde(positions)\n",
    "    return x_grid, y_grid, density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28506678-81c5-423a-95d1-d2dab27691ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 3.5\n",
    "height = width / 1.618\n",
    "# To take an overview of the ISDB and EDB\n",
    "# Param: FS_E_LIBRARY,FS_IS0_LIBRARY,FS_IS1_LIBRARY,FS_IS2_LIBRARY,\n",
    "# Return: kdeplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa625d7e-9b77-4b7a-8e4d-f247289c0ce8",
   "metadata": {},
   "source": [
    "## EDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48684b-d876-437a-9a40-b522bffd34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "E_pm,E_npeak,E_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_E_LIBRARY,total = len(FS_E_LIBRARY)):\n",
    "    E_pm.append(SPECTRUM['precursor_mz'])\n",
    "    E_npeak.append(SPECTRUM['n_peak'])\n",
    "    E_entropy.append(SPECTRUM['entropy'])\n",
    "E_DF = pd.DataFrame({\n",
    "    'entropy': E_entropy,\n",
    "    'PM': E_pm,\n",
    "    'NPEAK':E_npeak\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc9063-b51f-468e-8227-65057717d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample\n",
    "sample_size = 50000  # 选择一个合适的样本大小\n",
    "sample_df = E_DF.sample(n=sample_size)\n",
    "\n",
    "plt.figure(figsize=(width * 2, height * 2))\n",
    "kde = sns.kdeplot(\n",
    "    data=sample_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    # cut=0,\n",
    "    cbar=True,\n",
    "    legend=False,\n",
    "    color = '#E84445'\n",
    ")\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/E_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7c0e4-af7f-44fb-9ffd-e4a708b7bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculate kde density\n",
    "x_grid, y_grid, density = kde_density(E_entropy,E_pm)\n",
    "\n",
    "# 绘制图形\n",
    "plt.figure(figsize=(width * 3, height * 2))\n",
    "contour = plt.contourf(x_grid, y_grid, density.reshape(x_grid.shape),cmap='Greys')\n",
    "# contour.set_clim(vmin=0, vmax=0.005) \n",
    "plt.gcf().set_facecolor('white')  # set the figure background as white\n",
    "plt.gca().set_facecolor('white')  # set the axis backgroud as white\n",
    "plt.colorbar(label='Density')\n",
    "# plt.xlabel('Entropy')\n",
    "# plt.ylabel('PM')\n",
    "# plt.ylim(0, 100)\n",
    "plt.show()\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c25b7-55a7-4054-8bb0-3b64c61835ba",
   "metadata": {},
   "source": [
    "## ISDB_e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee690e9-54ce-4204-ba64-cbd88cf8794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB_e0\n",
    "t = time.time()\n",
    "IS0_pm,IS0_npeak,IS0_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_IS0_LIBRARY,total = len(FS_IS0_LIBRARY)):\n",
    "    IS0_pm.append(SPECTRUM['precursor_mz'])\n",
    "    IS0_npeak.append(SPECTRUM['n_peak'])\n",
    "    IS0_entropy.append(SPECTRUM['entropy'])\n",
    "IS0_DF = pd.DataFrame({\n",
    "    'entropy': IS0_entropy,\n",
    "    'PM': IS0_pm,\n",
    "    'NPEAK':IS0_npeak\n",
    "})\n",
    "\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4007cc-b3dd-4c46-8128-130fba90fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50000  # 选择一个合适的样本大小\n",
    "i0_df = IS0_DF.sample(n=sample_size, random_state=42)\n",
    "width = 3.5\n",
    "height = width / 1.618\n",
    "plt.figure(figsize=(width*2 , height*2))\n",
    "kde = sns.kdeplot(\n",
    "    data=i0_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    cbar=True,\n",
    "    # cut=0,\n",
    "    color = '#1999B2'\n",
    ")\n",
    "\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/is0_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a47a1-9e6e-4cce-9e34-9bc5bc352624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculate kde density\n",
    "x_grid, y_grid, density = kde_density(IS0_DF['entropy'].values,IS0_DF['PM'].values)\n",
    "\n",
    "# 绘制图形\n",
    "plt.figure(figsize=(width * 3, height * 2))\n",
    "contour = plt.contourf(x_grid, y_grid, density.reshape(x_grid.shape),cmap='Greys')\n",
    "contour.set_clim(vmin=0, vmax=0.005) \n",
    "\n",
    "plt.gcf().set_facecolor('white')  # set the figure background as white\n",
    "plt.gca().set_facecolor('white')  # set the axis backgroud as white\n",
    "plt.colorbar(label='Density')\n",
    "\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('PM')\n",
    "plt.ylim(0, 1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09220f-e173-4513-a749-06bac7247f46",
   "metadata": {},
   "source": [
    "## ISDB_e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94130247-a2d6-47e1-8868-51421d4974ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB_e1\n",
    "t = time.time()\n",
    "IS1_pm,IS1_npeak,IS1_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_IS1_LIBRARY,total = len(FS_IS1_LIBRARY)):\n",
    "    IS1_pm.append(SPECTRUM['precursor_mz'])\n",
    "    IS1_npeak.append(SPECTRUM['n_peak'])\n",
    "    IS1_entropy.append(SPECTRUM['entropy'])\n",
    "IS1_DF = pd.DataFrame({\n",
    "    'entropy': IS1_entropy,\n",
    "    'PM': IS1_pm,\n",
    "    'NPEAK':IS1_npeak\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7b6f8-219f-4adb-97b7-437f101ab04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50000  # 选择一个合适的样本大小\n",
    "i1_df = IS1_DF.sample(n=sample_size)\n",
    "\n",
    "plt.figure(figsize=(width*2 , height*2))\n",
    "kde = sns.kdeplot(\n",
    "    data=i1_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    # cut=0,\n",
    "    cbar=True,\n",
    "    legend=False,\n",
    "    color = '#95BCE5'\n",
    ")\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/is1_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e23f0-d7d6-47b2-b74a-2ecf727bda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculate kde density\n",
    "x_grid, y_grid, density = kde_density(IS1_DF['entropy'].values,IS1_DF['PM'].values)\n",
    "\n",
    "# 绘制图形\n",
    "plt.contourf(x_grid, y_grid, density.reshape(x_grid.shape),cmap='Greys')\n",
    "plt.gcf().set_facecolor('white')  # set the figure background as white\n",
    "plt.gca().set_facecolor('white')  # set the axis backgroud as white\n",
    "plt.colorbar(label='Density')\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('PM')\n",
    "plt.show()\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014763a-2b67-4c7a-b4fe-55cc05e089c5",
   "metadata": {},
   "source": [
    "## ISDB_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afa748-030f-4e7d-9715-72d86503fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB_e2\n",
    "t = time.time()\n",
    "IS2_pm,IS2_npeak,IS2_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_IS2_LIBRARY,total = len(FS_IS2_LIBRARY)):\n",
    "    IS2_pm.append(SPECTRUM['precursor_mz'])\n",
    "    IS2_npeak.append(SPECTRUM['n_peak'])\n",
    "    IS2_entropy.append(SPECTRUM['entropy'])\n",
    "IS2_DF = pd.DataFrame({\n",
    "    'entropy': IS2_entropy,\n",
    "    'PM': IS2_pm,\n",
    "    'NPEAK':IS2_npeak\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea6970-c39e-4e0f-8014-db837e8bb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100000  # 选择一个合适的样本大小\n",
    "i2_df = IS2_DF.sample(n=sample_size)\n",
    "\n",
    "plt.figure(figsize=(width*2 , height*2))\n",
    "kde = sns.kdeplot(\n",
    "    data=i2_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    # cut=0,\n",
    "    cbar=True,\n",
    "    legend=False,\n",
    "    color = '#F39DA0'\n",
    ")\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/is2_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585112f8-b000-48e8-807c-3eebda0bc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculate kde density\n",
    "x_grid, y_grid, density = kde_density(IS2_DF['entropy'].values,IS2_DF['PM'].values)\n",
    "\n",
    "# 绘制图形\n",
    "plt.contourf(x_grid, y_grid, density.reshape(x_grid.shape),cmap='Greys')\n",
    "plt.gcf().set_facecolor('white')  # set the figure background as white\n",
    "plt.gca().set_facecolor('white')  # set the axis backgroud as white\n",
    "plt.colorbar(label='Density')\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('PM')\n",
    "plt.show()\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69e634-221c-4f4f-a958-b21cb405afe3",
   "metadata": {},
   "source": [
    "# Accuracy of ISDB\n",
    "## Inner consistency of ISDB\n",
    "### Spectral similarity of ISDB_e0/e1/e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c016da-b02a-45e3-9999-c046155380ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cluster the in-silico spectra to find high-accuracy spectra\n",
    "Param: e_search,is0_search,is1_search,is2_search; FS_E_LIBRARY,FS_IS0_LIBRARY,FS_IS1_LIBRARY,FS_IS2_LIBRARY\n",
    "Scripts: ICofIS.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401535c-bc64-4384-9e26-daec8380d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../msdb/lib_matrix/test.npy',SPEC_IS0_SIM_MATRIC)\n",
    "test_matrix= np.load('../msdb/lib_matrix/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2245d-13f7-47d4-8432-9aed4a1f9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "icis0 = functions_new.json_load('../msdb/data/ICofIS/is0_Id2Smile.json')\n",
    "icis1 = functions_new.json_load('../msdb/data/ICofIS/is1_Id2Smile.json')\n",
    "icis2 = functions_new.json_load('../msdb/data/ICofIS/is2_Id2Smile.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf96da5-9649-4674-b119-d8a895c75665",
   "metadata": {},
   "source": [
    "### Chemical similarity matrices\n",
    "`ICofIS_ChemSim.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aad24-c172-45ed-bbba-95922e2edea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fp databased by FPsim2\n",
    "# Param: Index-to-SMILE, specific finger print type(Morgan_radius2_fpSize1024)\n",
    "# return: fp database file\n",
    "t = time.time() \n",
    "EL = 2 # Energy Lever\n",
    "ID2SMILE = functions_new.json_load(f'../msdb/data/ICofIS/is{EL}_Id2Smile.json')\n",
    "FPDB_FILE = f'../msdb/data/ICofIS/chem/is{EL}_fp_db.h5'\n",
    "OUTPUT_MATRIX = f'../msdb/data/ICofIS/chem/is{EL}_ICofIS.npy'\n",
    "\n",
    "IDX2SMILE = [[s['smile'],idx] for idx,s in enumerate(ID2SMILE)]\n",
    "\n",
    "if not os.path.exists(FPDB_FILE):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE, \n",
    "        filename=FPDB_FILE,\n",
    "        mol_format='smiles', # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8060b-6f66-4b5c-ba7d-542cf6e9b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate structural similarity pair >= specific threshold (Dice_radius2_0.75)\n",
    "fpe = FPSim2Engine(FPDB_FILE)\n",
    "hit_dict = {}\n",
    "for idx,s in tqdm(enumerate(IDX2SMILE),total = len(IDX2SMILE)):\n",
    "    SMILE = s[0]\n",
    "    results = fpe.similarity(SMILE, threshold=0.75, metric='dice', n_workers=1)# [(LIBidx,similarity1),(),...]\n",
    "    fpidx_list = [x[0] for x in results]\n",
    "    fpsim_list = [x[1] for x in results]\n",
    "    if fpidx_list:\n",
    "        hit_dict[idx] = {'idx':fpidx_list,'sim_list':fpsim_list} # {LIBidx: {},{},..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741f8b3-6b4b-4601-87db-db0077b3dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matrix\n",
    "ECHEM_MATRIX  = np.full((len(IDX2SMILE),len(IDX2SMILE)), 0.0, dtype=float) \n",
    "for key, value in hit_dict.items():\n",
    "    QueryIdx = key\n",
    "    MatchIdxs = value['idx']\n",
    "    MatchSim = value['sim_list']\n",
    "    for idx, MatchIdx in enumerate(MatchIdxs):\n",
    "        ECHEM_MATRIX[QueryIdx,MatchIdx] = MatchSim[idx]\n",
    "np.save(OUTPUT_MATRIX,ECHEM_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48fa34-f272-47fb-a7a6-07d30d86554a",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "`ICofIS_networking.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d256b30-b923-4a2b-99aa-e4347fc6eec5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd517d1-dc08-46c4-b2c1-28ea70229d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9ab97-dbc6-46a3-8cb1-f3e538b3f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f'../msdb/data/ICofIS/'\n",
    "IDXtoFID = {}\n",
    "for idx,s in enumerate(FS_IS_LIBRARY):\n",
    "    IDXtoFID[idx] = s['id']\n",
    "CCMSIDtoIDX = {value: key for key, value in IDXtoFID.items()}\n",
    "with open('../msdb/data/isdb/IDXtoFID.json','w') as f:\n",
    "    json.dump(IDXtoFID,f)\n",
    "\n",
    "\n",
    "ISID_SMILE = functions_new.json_load('../msdb/data/ICofIS/is0_Id2Smile.json')\n",
    "ESPEC_MATRIX = np.load(f'../msdb/data/ICofIS/entropy_is{EL}_sim_icofis.npy')\n",
    "EMP_MATRIX = np.load(f'../msdb/data/ICofIS/entropy_is{EL}_peak_icofis.npy')\n",
    "ECHEM_MATRIX = np.load(f'../msdb/data/ICofIS/chem/is{EL}_ICofIS.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b5217d-9860-45f0-9ec4-993f4b17f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load search matrix\n",
    "# THRESHOLDs = list(np.arange(0, 1.1, 0.001))\n",
    "# peak_threshold = list(np.arange(1,11,1))\n",
    "\n",
    "G1,G2,G3,G4 = topology.get_groups() # Load algorithms\n",
    "\n",
    "SHARED_PEAKs = False\n",
    "SEARCH_ALGORITHMs = ['entropy']\n",
    "DIR = '../msdb/data/std/SearchMatrix/'\n",
    "\n",
    "ISM_RES = []\n",
    "for ALGO in tqdm(SEARCH_ALGORITHMs,total = len(SEARCH_ALGORITHMs)):\n",
    "    # Load Spec search matrices:\n",
    "    try:\n",
    "        ESPEC_MATRIX = np.load(f'../msdb/data/ICofIS/entropy_is{EL}_sim_icofis.npy')\n",
    "        EMP_MATRIX = np.load(f'../msdb/data/ICofIS/entropy_is{EL}_peak_icofis.npy')\n",
    "        ECHEM_MATRIX = np.load(f'../msdb/data/ICofIS/chem/is{EL}_ICofIS.npy')\n",
    "        \n",
    "        if SHARED_PEAKs:\n",
    "            EMIDXs = np.full(ESPEC_MATRIX.shape[0], 0, dtype=int)   \n",
    "            EMaxSpecSim  = np.full(ESPEC_MATRIX.shape[0], 0.0, dtype=float) \n",
    "            EMaxChemSim = np.full(ESPEC_MATRIX.shape[0], 0.0, dtype=float)\n",
    "            \n",
    "            for idx,EMP_ARR in enumerate(EMP_MATRIX):\n",
    "                cols = np.where(EMP_ARR >=6)[0] # <tuple> Min matched peaks >= 5\n",
    "                if cols.any(): # \n",
    "                    FilColIdx = np.argmax(ESPEC_MATRIX[idx, cols])\n",
    "                    best_col = cols[FilColIdx]\n",
    "                    EMIDXs[idx] = best_col\n",
    "                    EMaxSpecSim[idx]  =  ESPEC_MATRIX[idx, best_col]\n",
    "                    EMaxChemSim[idx] = ECHEM_MATRIX[idx, best_col]\n",
    "            ELables = [1 if x >= 0.75 else 0 for x in EMaxChemSim] # Chem sim ≥ 0.75 is considered true positive\n",
    "            \n",
    "            # ROC_AUC curve\n",
    "            FPRs, TPRs, THRESHOLDs = roc_curve(ELables, EMaxSpecSim)\n",
    "            AUC = auc(FPRs,TPRs)\n",
    "            # J = TPRs - FPRs # # Youden's J to find the optimal threshold\n",
    "            # optimal_idx = np.argmax(J)\n",
    "            OT = optimal_threshold[ALGO] # optimal spectral similarity threshold \n",
    "            Y_PREDCTIONs = [1 if x >= OT else 0 for x in EMaxSpecSim] # Spectral sim ≥ threholds is considered as 1 \n",
    "            TN, FP, FN, TP  = confusion_matrix(ELables, Y_PREDCTIONs).ravel()\n",
    "            FDR = FP/(FP+TP) \n",
    "\n",
    "            \n",
    "        else:\n",
    "            # EMaxIdx = []\n",
    "            \n",
    "            EMaxIdx = [np.argmax(arr) for arr in ESPEC_MATRIX] # Top1 scoring\n",
    "            EMaxSpecSim = [ESPEC_MATRIX[idx][EMaxIdx[idx]] for idx in range(len(EMaxIdx))] # Spectral similarity with top 1 match\n",
    "            EMaxChemSim = [ECHEM_MATRIX[idx][EMaxIdx[idx]] for idx in range(len(EMaxIdx))] # Chemical dice simialrity with top 1 match\n",
    "            ELables = [1 if x >= 0.75 else 0 for x in EMaxChemSim] \n",
    "        \n",
    "            # ROC_AUC curve\n",
    "            FPRs, TPRs, THRESHOLDs = roc_curve(ELables, EMaxSpecSim)\n",
    "            AUC = auc(FPRs,TPRs)\n",
    "            \n",
    "            J = TPRs - FPRs # # Youden's J to find the optimal threshold\n",
    "            optimal_idx = np.argmax(J)\n",
    "            OT = THRESHOLDs[optimal_idx] # optimal spectral similarity threshold \n",
    "            Y_PREDCTIONs = [1 if x >= OT else 0 for x in EMaxSpecSim] # Spectral sim ≥ threholds is considered as 1 \n",
    "            TN, FP, FN, TP  = confusion_matrix(ELables, Y_PREDCTIONs).ravel()\n",
    "            FDR = FP/(FP+TP) \n",
    "        ISM_RES.append({'library':'in-silico',\n",
    "                       'spectral_algorithm':ALGO,\n",
    "                       'optimal_threshold': OT,\n",
    "                        'TN':TN,'FP':FP,'FN':FN,'TP':TP,\n",
    "                       'FDR':FDR,'TPR':TPRs[optimal_idx],'FPR':FPRs[optimal_idx],\n",
    "                        'AUC':AUC\n",
    "                       })\n",
    "    except:print(ALGO)\n",
    "\n",
    "ISM_DF = pd.DataFrame(ISM_RES).sort_values(by='TP', ascending=False)\n",
    "ISM_DF.to_csv(f'../msdb/data/ICofIS/is{EL}_ICofIS.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eef124-e410-432c-961c-917d137c379b",
   "metadata": {},
   "source": [
    "### PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe8e98-de97-4e55-8e37-c3f33dd14e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp2arr(fp):\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f386d3-ba32-400a-8bfd-3586d74d0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sample represent the total database\n",
    "# icis0, icis1, icis2 <dict> FS_IS0_LIBRARY\n",
    "class1=[]\n",
    "molecules=[]\n",
    "ecfp_1024=[]\n",
    "X = []\n",
    "CLASS1 = 'class1'\n",
    "CLASS2 = 'class2'\n",
    "for i in trange(len(icis0)):\n",
    "    try:\n",
    "        SMILE = icis0[i]['smile']\n",
    "        mol = Chem.MolFromSmiles(SMILE)\n",
    "        ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "        class1.append(CLASS1)\n",
    "        X.append(np.array(fp2arr(ecfp)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in trange(len(FS_IS0_LIBRARY)):\n",
    "    try:\n",
    "        SMILE = FS_IS0_LIBRARY[i]['smile']\n",
    "        mol = Chem.MolFromSmiles(SMILE)\n",
    "        ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "        class1.append(CLASS2)\n",
    "        X.append(np.array(fp2arr(ecfp)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "reduced_X = pca.transform(X)\n",
    "\n",
    "# Access the explained variance ratio of each principal component\n",
    "explained_var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio of each principal component\n",
    "pc1 = ''\n",
    "pc2 = ''\n",
    "pc3 = ''\n",
    "for i, var_ratio in enumerate(explained_var_ratio):\n",
    "    print(f'Principal Component {i + 1}: Explained Variance Ratio = {var_ratio:.4f}')\n",
    "    if i+1 == 1:\n",
    "        pc1 = f'{(var_ratio*100):.2f}%'\n",
    "    if i+1 == 2:\n",
    "        pc2 = f'{(var_ratio*100):.2f}%'\n",
    "    if i+1 == 3:\n",
    "        pc3 = f'{(var_ratio*100):.2f}%'\n",
    "    if i+1 > 2:break\n",
    "\n",
    "print(pc1,pc2,pc3)\n",
    "red_x, red_y, red_z= [], [], []\n",
    "blue_x, blue_y, blue_z = [], [], []\n",
    "green_x, green_y, green_z = [], [], []\n",
    "\n",
    "for i in trange(len(reduced_X)):\n",
    "    if class1[i] == CLASS1:\n",
    "        red_x.append(reduced_X[i][0])\n",
    "        red_y.append(reduced_X[i][1])\n",
    "\n",
    "    elif class1[i] == CLASS2:\n",
    "        blue_x.append(reduced_X[i][0])\n",
    "        blue_y.append(reduced_X[i][1])\n",
    "  \n",
    "\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(red_x, red_y, c='#1A51AD', marker='o', label='selected',alpha=0.5)\n",
    "ax.scatter(blue_x, blue_y, c='gray', marker='o', label='ISDB',alpha=0.015)\n",
    "ax.legend()\n",
    "ax.set_xlabel(f'PC1 ({pc1})')\n",
    "ax.set_ylabel(f'PC2 ({pc2})')\n",
    "ax.set_title('2D PCA')\n",
    "\n",
    "# plt.savefig('scaffolds.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443786e0-447d-4d95-9875-5f077b0bb5e4",
   "metadata": {},
   "source": [
    "## hqtof search against IS\n",
    "### Non-redundant GNPS library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816bfc1-388a-46ce-9de3-f206891c06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and retain unique compounds with smiles (47193)\n",
    "SMILEs = []\n",
    "CUR_FS_E_LIBRARY = []\n",
    "for SPEC in tqdm(FS_E_LIBRARY,total=len(FS_E_LIBRARY)):\n",
    "    SMILE = SPEC['smile']\n",
    "    if SMILE not in SMILEs:\n",
    "        SMILEs.append(SMILE)\n",
    "        CUR_FS_E_LIBRARY.append(SPEC)\n",
    "        \n",
    "# Save as json file\n",
    "for SPEC in tqdm(CUR_FS_E_LIBRARY,total = len(CUR_FS_E_LIBRARY)):\n",
    "    PEAKS = SPEC['peaks'] \n",
    "    SPEC['peaks'] = PEAKS.tolist()\n",
    "\n",
    "FS_GNPS_LIBRARY_OUTPUT0 = '../msdb/FS_edb_nr.json'\n",
    "with open(FS_GNPS_LIBRARY_OUTPUT0, \"w\") as f:\n",
    "    json.dump(CUR_FS_E_LIBRARY, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f5fd5-4168-4f3f-a868-95f0421a0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered library\n",
    "t = time.time()\n",
    "FS_E_LIBRARY_NR = functions_new.json_load('../msdb/FS_hqtof.json')\n",
    "e_nr_search = FlashEntropySearch()\n",
    "FS_E_LIBRARY_NR = e_nr_search.build_index(FS_E_LIBRARY_NR)\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc237b2-b776-4d24-8e20-ccb6d30fd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Match against the ISDB e0/e1/e2 by modified cosine and entropy\n",
    "## EmIS.py\n",
    "EmI_SIM_MATRIC = np.empty((0, len(FS_IS1_LIBRARY)))\n",
    "EmI_IS_NPEAK_MATRIC = np.empty((0, len(FS_IS1_LIBRARY)))\n",
    "for SPEC in tqdm(FS_E_LIBRARY_NR,total = len(FS_E_LIBRARY_NR)):\n",
    "    PM = SPEC['precursor_mz']\n",
    "    PEAKs = SPEC['peaks']\n",
    "    \n",
    "    SIM_ARRAY = is1_search.identity_search(\n",
    "        precursor_mz = PM,\n",
    "        peaks = PEAKs,\n",
    "        ms1_tolerance_in_da = 0.02,\n",
    "        ms2_tolerance_in_da = 0.02,\n",
    "        output_matched_peak_number = False)\n",
    "        \n",
    "    EmI_SIM_MATRIC = np.vstack((EmI_SIM_MATRIC,SIM_ARRAY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b210eb-94a4-4a29-a1bf-f06f2eb6c50c",
   "metadata": {},
   "source": [
    "### Chemical similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51c82d-5a6b-4190-902f-4f67b5c15d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_emis:h qtof (2538, 454887)\n",
    "# Create fp databased by FPsim2\n",
    "# Param: Index-to-SMILE, specific finger print type(Morgan_radius2_fpSize1024)\n",
    "# return: fp database file\n",
    "t = time.time() \n",
    "DIR = f'../msdb/data/ICofIS/'\n",
    "EL = 2 # Energy Level 0,1,2\n",
    "FPDB_FILE = os.path.join(DIR,f'chem/is{EL}_fp_db_emis.h5')\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_MATRIX = f'../msdb/data/ICofIS/chem/is{EL}_emis.npy'\n",
    "\n",
    "IDX2SMILE = [[s['smile'],idx] for idx,s in enumerate(FS_IS2_LIBRARY)]\n",
    "\n",
    "if not os.path.exists(FPDB_FILE):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE, \n",
    "        filename=FPDB_FILE,\n",
    "        mol_format='smiles', # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a0e69-f928-43d2-9831-a8676acccb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate structural similarity pair >= specific threshold (Dice_radius2_0.75)\n",
    "# FS_SPECTRA: hqtof\n",
    "fpe = FPSim2Engine(FPDB_FILE)\n",
    "hit_dict = {}\n",
    "for idx,s in tqdm(enumerate(FS_SPECTRA),total = len(FS_SPECTRA)):\n",
    "    SMILE = s['smile']\n",
    "    results = fpe.similarity(SMILE, threshold=0.75, metric='dice', n_workers=1)# [(LIBidx,similarity1),(),...]\n",
    "    fpidx_list = [x[0] for x in results]\n",
    "    fpsim_list = [x[1] for x in results]\n",
    "    if fpidx_list:\n",
    "        hit_dict[idx] = {'idx':fpidx_list,'sim_list':fpsim_list} # {LIBidx: {},{},..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3319c1-3143-48bb-ba96-882391798d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matrix\n",
    "ECHEM_MATRIX  = np.full((len(FS_SPECTRA),len(IDX2SMILE)), 0.0, dtype=float) \n",
    "for key, value in hit_dict.items():\n",
    "    QueryIdx = key\n",
    "    MatchIdxs = value['idx']\n",
    "    MatchSim = value['sim_list']\n",
    "    for idx, MatchIdx in enumerate(MatchIdxs):\n",
    "        ECHEM_MATRIX[QueryIdx,MatchIdx] = MatchSim[idx]\n",
    "np.save(OUTPUT_MATRIX,ECHEM_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0333e87-9712-46f0-837f-eb79e200406a",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82570f-a121-4c3c-9647-29fddc15280e",
   "metadata": {},
   "source": [
    "### Match against the ISDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2eaa8a-d228-4586-aabd-2e03a153b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_SIM_MATRIX = []\n",
    "CUR_NPEAK_MATRIX = []\n",
    "for SPEC in tqdm(FS_E_LIBRARY_NR,total = len(FS_E_LIBRARY_NR)):\n",
    "    PM = SPEC['precursor_mz']\n",
    "    PEAKs = SPEC['peaks']\n",
    "    SIM_ARRAY, NPEAK_ARRAY = is1_search.open_search(\n",
    "    precursor_mz=PM, peaks=PEAKs,\n",
    "    ms1_tolerance_in_da=0.02, ms2_tolerance_in_da=0.02,\n",
    "    output_matched_peak_number=True)\n",
    "    SIM_ARRAY = np.round(SIM_ARRAY.astype(float), decimals=2)\n",
    "    CUR_SIM_MATRIX.append(SIM_ARRAY)\n",
    "    CUR_NPEAK_MATRIX.append(NPEAK_ARRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61830f-f67e-4d0d-8172-52362c92b131",
   "metadata": {},
   "source": [
    "## Similarity between in-silico and experimental spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e69162-622d-459b-aaa8-a9c8b63112ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate\n",
    "temp = functions_new.json_load('../msdb/FS_edb_smi.json')\n",
    "e_search = FlashEntropySearch()\n",
    "FS_E_LIBRARY = e_search.build_index(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b07a163c-4952-458f-b257-5f8e0d22b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_E_LIBRARY = list({s['smile']: s for s in FS_E_LIBRARY}.values()) # Retain spectra with non-redunant similes\n",
    "ISDB_list = list(ISDB_INFO) # Keys of ISDB_INFO <list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c00dd9af-c239-4a05-b612-e994337921f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:25:01] Explicit valence for atom # 20 N, 5, is greater than permitted\n",
      "[00:27:14] Explicit valence for atom # 24 N, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 3.45 min\n"
     ]
    }
   ],
   "source": [
    "# gnps_is:h qtof (47192, 467124)\n",
    "# Create fp databased by FPsim2\n",
    "# Param: Index-to-SMILE, specific finger print type(Morgan_radius2_fpSize1024)\n",
    "# return: fp database file\n",
    "t = time.time() \n",
    "DIR = f'../msdb/data/ICofIS/'\n",
    "FPDB_FILE = os.path.join(DIR,f'chem/fp_db_gnps_is.h5')\n",
    "OUTPUT_MATRIX = os.path.join(DIR,f'chem/gnps_is.npy')\n",
    "\n",
    "IDX2SMILE = []\n",
    "for idx, (key, values) in enumerate(ISDB_INFO.items()):\n",
    "    IDX2SMILE.append([values['smiles'],idx])\n",
    "\n",
    "if not os.path.exists(FPDB_FILE):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE, \n",
    "        filename=FPDB_FILE,\n",
    "        mol_format='smiles', # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b5a6c37-a384-47c7-83b6-f5f84d68421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find identical GNPS-smile in isdb\n",
    "# Calculate structural similarity pair >= specific threshold (Dice_radius2_1)\n",
    "# FS_SPECTRA: hqtof\n",
    "fpe = FPSim2Engine(FPDB_FILE)\n",
    "hit_dict = {}\n",
    "for idx,s in enumerate(dup_E_LIBRARY):\n",
    "    SMILE = s['smile']\n",
    "    results = fpe.similarity(SMILE, threshold=1, metric='dice', n_workers=1)# [(LIBidx,similarity1),(),...]\n",
    "    fpidx_list = [x[0] for x in results]\n",
    "    fpsim_list = [x[1] for x in results]\n",
    "    if fpidx_list:\n",
    "        hit_dict[idx] = {'idx':fpidx_list,'sim_list':fpsim_list} # {LIBidx: {},{},..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "29148faf-5193-4c20-86d5-b0e8c5f38836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18983 gnps-smiles found identical match in isdb\n",
    "ALGO = 'entropy'\n",
    "for key, values in hit_dict.items():\n",
    "    dup_E_SPECTRUM = dup_E_LIBRARY[key]\n",
    "    PM = dup_E_SPECTRUM['precursor_mz']\n",
    "    SPEC = dup_E_SPECTRUM['peaks']\n",
    "    SPEC = spectral_entropy.clean_spectrum(SPEC, max_mz=PM+0.01) # MS2 spectrum clean by normalizing and removing signals with intensity less than 1% of the base peak\n",
    "    SPECTRUM = Spectrum(mz=np.array(SPEC[:, 0],dtype = float),\n",
    "                  intensities=np.array(SPEC[:, 1],dtype = float),\n",
    "                  metadata={\"precursor_mz\": PM})\n",
    "    \n",
    "    \n",
    "    ISDB_idx = values['idx'][0]\n",
    "    ISDB_ID = ISDB_list[ISDB_idx]\n",
    "    e0_ms2,e0_spectrum,e1_ms2,e1_spectrum,e2_ms2,e2_spectrum = functions_new.get_spectra_from_isinfo(ISDB_INFO,ISDB_ID)\n",
    "\n",
    "    SIM0, MP0 = functions_new.clac_spec_sim(SPEC,SPECTRUM,e0_ms2,e0_spectrum,ALGO)\n",
    "    SIM1, MP1 = functions_new.clac_spec_sim(SPEC,SPECTRUM,e1_ms2,e1_spectrum,ALGO)\n",
    "    SIM2, MP2 = functions_new.clac_spec_sim(SPEC,SPECTRUM,e2_ms2,e2_spectrum,ALGO)\n",
    "\n",
    "    dup_E_SPECTRUM[f'{ALGO}_sim0'] = round(SIM0,2)\n",
    "    dup_E_SPECTRUM[f'{ALGO}_mp0'] = MP0\n",
    "    dup_E_SPECTRUM[f'{ALGO}_sim1'] = round(SIM1,2)\n",
    "    dup_E_SPECTRUM[f'{ALGO}_mp1'] = MP1\n",
    "    dup_E_SPECTRUM[f'{ALGO}_sim2'] = round(SIM2,2)\n",
    "    dup_E_SPECTRUM[f'{ALGO}_mp2'] = MP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31e2586f-69e5-4888-bd2b-b5473b9418d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'CCMSLIB00000427077', 'precursor_mz': 32.05, 'peaks': array([[30.,  1.]], dtype=float32), 'smile': 'CN', 'charge': 1, 'ion_mode': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "dup_E_LIBRARY[19]\n",
    "for r in dup_E_LIBRARY:\n",
    "    print(r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "55e2ca8d-bdb3-423e-8a61-cf95399b5064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09993151767370806% pairs higher than 0.6\n",
      "0.276563240794395% pairs higher than 0.35 and lower than 0.6\n",
      "0.6691250065848391% pairs lower than 0.35\n"
     ]
    }
   ],
   "source": [
    "ALGO = 'peak_percentage'\n",
    "keys = [f'{ALGO}_sim0',f'{ALGO}_mp0',\n",
    "        f'{ALGO}_sim1',f'{ALGO}_mp1',\n",
    "        f'{ALGO}_sim2',f'{ALGO}_mp2']\n",
    "stats = {keys[0]:[],keys[1]:[],keys[2]:[],keys[3]:[],keys[4]:[],keys[5]:[]}\n",
    "for SPECTRUM in dup_E_LIBRARY:\n",
    "    for key in keys:\n",
    "        try:\n",
    "            stats[key].append(SPECTRUM[key])\n",
    "        except:\n",
    "            pass\n",
    "idx1,idx3,idx5 = 0,2,4\n",
    "total = len(stats[keys[idx1]])\n",
    "print(f'{len([x for x in stats[keys[idx5]] if x >= 0.6])/total}% pairs higher than 0.6')\n",
    "print(f'{len([x for x in stats[keys[idx1]] if 0.7 > x >= 0.35])/total}% pairs higher than 0.35 and lower than 0.6')\n",
    "print(f'{len([x for x in stats[keys[idx1]] if 0.35 > x])/total}% pairs lower than 0.35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "75cbe14a-eba7-4e6b-b351-5c4d128cdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个共享 x 轴的双 y 轴图\n",
    "plt.rcParams['font.sans-serif'] = ['Arial'] \n",
    "fig, ax1 = plt.subplots(figsize=(3, 6))\n",
    "idx1,idx2 = 4,5\n",
    "x_ls = np.zeros(len(stats[keys[idx1]]))      # 全 0\n",
    "x_hs = np.ones(len(stats[keys[idx2]]))       # 全 1\n",
    "\n",
    "# 绘制 LS_values 的小提琴图\n",
    "# sns.violinplot(y=stats[keys[0]], color='blue', inner=None, ax=ax1, width=0.5)\n",
    "sns.violinplot(x=x_ls, y=stats[keys[idx1]],\n",
    "               color='#F5A889', inner=None, width=0.4, ax=ax1)\n",
    "ax1.set_title(f\"{keys[idx1]}\")\n",
    "ax1.set_ylabel(\"Spectral similarity\", color='black')\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# for spine in ax1.spines.values(): # 隐藏 ax1 的边框\n",
    "#     spine.set_visible(False)\n",
    "ax1.xaxis.set_ticks_position('none')  # 隐藏 x 轴刻度\n",
    "ax1.yaxis.set_ticks_position('none')  # 隐藏 y 轴刻度\n",
    "\n",
    "ax2 = ax1.twinx() # 创建第二个 y 轴\n",
    "ax2.spines['right'].set_position(('outward', -3)) # 调整 ax2 的位置，使其更靠近 ax1\n",
    "\n",
    "# 绘制 HS_values 的小提琴图\n",
    "sns.violinplot(x=x_hs, y=stats[keys[idx2]],\n",
    "               color='#ACD6EC', inner=None, width=0.4, ax=ax2)\n",
    "ax2.set_ylabel(\"Shared peaks\", color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# 隐藏 ax2 的边框\n",
    "# for spine in ax2.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(DIR,f'pic/violion_{keys[idx1]}.png'), dpi=500, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ea8a0-535f-4d38-907c-9c34a05e491a",
   "metadata": {},
   "source": [
    "# Hqtof spectral sim matrix\n",
    "1. Spectral simialrity matrices\n",
    "\n",
    "2. Structural similarity matrices\n",
    "\n",
    "* Tanimoto\n",
    "* Maximum Common Substructure jaccard oefficient (MCS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0cf6f6-79dc-4a89-b652-92f2c5bc44ce",
   "metadata": {},
   "source": [
    "## Spectral similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2740848-a5f0-4e2d-83db-2a5d7c14908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "hqtof_pair = FlashEntropySearchCore()\n",
    "(e_ions_mz_idx_start,e_ions_mz,e_ions_intensity,e_ions_spec_idx,\n",
    "e_nl_mass_idx_start,e_nl_mass,e_nl_intensity,e_nl_spec_idx,e_ions_idx_for_nl,\n",
    ") = hqtof_pair.build_index(FS_SPECTRA)\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da5a09-f964-4778-9464-b41d5b665925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Compare_dict\n",
    "t = time.time()\n",
    "# Param\n",
    "# Stack lib ions\n",
    "compare_dict = \n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a2c79-0548-4a21-97e6-4a6e08d99ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle file\n",
    "with open('../msdb/data/hqtof/compare_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(compare_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df159a7-0143-4a5d-bfa7-800f48f90cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "with open('../msdb/data/hqtof/compare_dict.pkl', 'rb') as f:\n",
    "    compare_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721b403-596b-443f-9620-e75eaa8fbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1,G2,G3,G4 = topology.get_groups()\n",
    "ALGOs = G1 + G2 + G3 + G4 \n",
    "SEARCH_ALGOs = [sa for sa in ALGOs if sa not in ['modified_cosine','entropy','neutral_loss']]\n",
    "compare_dict = functions_new.json_load('../msdb/data/hqtof/compare_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e4033-5e26-40d1-8a06-04846d9f91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search\n",
    "t = time.time()\n",
    "SEARCH_ALGOs = ['entropy']\n",
    "\n",
    "cosine = CosineGreedy(tolerance=0.02)\n",
    "neutral_loss = NeutralLossesCosine(0.02)\n",
    "modified_cosine = ModifiedCosine(tolerance=0.02)\n",
    "\n",
    "for SEARCH_ALGO in SEARCH_ALGOs:\n",
    "    print(SEARCH_ALGO)\n",
    "    EMS2_RESULT = {}\n",
    "    EMS2_SIM_MATRIX = np.zeros((len(FS_SPECTRA), len(FS_SPECTRA)), dtype=float) # Initialize empty \n",
    "    EMS2_PEAK_MATRIX = np.zeros((len(FS_SPECTRA), len(FS_SPECTRA)), dtype=float)\n",
    "                                 \n",
    "    for query_idx, E_idxs in tqdm(compare_dict.items(),total = len(compare_dict)):\n",
    "        query_PM = FS_SPECTRA[query_idx]['precursor_mz']\n",
    "        query_PEAKS = FS_SPECTRA[query_idx]['peaks']\n",
    "\n",
    "        spectrum_1 = Spectrum(mz=np.array(query_PEAKS[:, 0],dtype = float),\n",
    "                              intensities=np.array(query_PEAKS[:, 1],dtype = float),\n",
    "                              metadata={\"precursor_mz\": query_PM})\n",
    "        \n",
    "        temp_SIM_ARR = np.zeros((1, len(FS_SPECTRA))) \n",
    "        temp_PEAK_ARR = np.zeros((1, len(FS_SPECTRA)))\n",
    "        for E_idx in E_idxs: # E_idxs\n",
    "            E_PM = FS_SPECTRA[E_idx]['precursor_mz']\n",
    "            E_PEAKS = FS_SPECTRA[E_idx]['peaks']\n",
    "            spectrum_2 = Spectrum(mz=np.array(E_PEAKS[:, 0],dtype = float),\n",
    "                                  intensities=np.array(E_PEAKS[:, 1],dtype = float),\n",
    "                                  metadata={\"precursor_mz\": E_PM})\n",
    "\n",
    "            if SEARCH_ALGO == 'modified_cosine':\n",
    "                    \n",
    "                score = modified_cosine.pair(spectrum_1, spectrum_2)\n",
    "                SPEC_SIM = score['score']\n",
    "                N_PEAK = score['matches']\n",
    "    \n",
    "                EMS2_SIM_MATRIX[query_idx,E_idx] = SPEC_SIM\n",
    "                EMS2_PEAK_MATRIX[query_idx,E_idx] = N_PEAK\n",
    "\n",
    "            elif SEARCH_ALGO == 'cosine':\n",
    "                score = cosine.pair(spectrum_1, spectrum_2)\n",
    "                \n",
    "                SPEC_SIM = score['score']\n",
    "                N_PEAK = score['matches']\n",
    "        \n",
    "                EMS2_SIM_MATRIX[query_idx,E_idx] = SPEC_SIM\n",
    "                EMS2_PEAK_MATRIX[query_idx,E_idx] = N_PEAK  \n",
    "                \n",
    "            elif SEARCH_ALGO == 'neutral_loss':\n",
    "                score = neutral_loss.pair(spectrum_1, spectrum_2)\n",
    "                \n",
    "                SPEC_SIM = score['score']\n",
    "                N_PEAK = score['matches']\n",
    "        \n",
    "                EMS2_SIM_MATRIX[query_idx,E_idx] = SPEC_SIM\n",
    "                EMS2_PEAK_MATRIX[query_idx,E_idx] = N_PEAK   \n",
    "            \n",
    "            # # if functions_new.calculate_ppm(query_PM,E_PM) <= 10:\n",
    "            else:\n",
    "                    \n",
    "                SPEC_SIM = similarity(query_PEAKS, E_PEAKS, method=SEARCH_ALGO, ms2_da=0.02)  \n",
    "                EMS2_SIM_MATRIX[query_idx,E_idx] = SPEC_SIM\n",
    "\n",
    "        \n",
    "    np.save(f'../msdb/data/hqtof/SpecSimMatrix/{SEARCH_ALGO}.npy',EMS2_SIM_MATRIX)\n",
    "    np.save(f'../msdb/data/hqtof/SpecSimMatrix/{SEARCH_ALGO}_mp.npy',EMS2_PEAK_MATRIX)\n",
    "\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d66495-490a-436c-895f-cee6eed97aff",
   "metadata": {},
   "source": [
    "## Pairwise calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997579d-4f04-4b0c-a449-c398dc5569bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra_from_einfo(EINFO,ID):\n",
    "    '''\n",
    "\n",
    "    :param einfo:\n",
    "    :param id:\n",
    "    :return:\n",
    "    '''\n",
    "    edb_pm = float(EINFO[ID]['PEPMASS'])\n",
    "    ESMILE = EINFO[ID]['SMILE']\n",
    "    temp = EINFO[ID]['MS2_SPECTRUM'] # <list>[[],[],...]\n",
    "    if type(temp) == str:\n",
    "        ESPEC = np.asarray(ast.literal_eval(temp)) # \"[[],[],[],...]\"\n",
    "    else:\n",
    "        ESPEC = temp\n",
    "    ESPEC = spectral_entropy.clean_spectrum(ESPEC, max_mz=edb_pm+0.01)\n",
    "    ESPECTRUM = Spectrum(mz=np.array(ESPEC[:, 0],dtype = float),\n",
    "                  intensities=np.array(ESPEC[:, 1],dtype = float),\n",
    "                  metadata={\"precursor_mz\": edb_pm,\"smile\":ESMILE})\n",
    "\n",
    "    return ESPEC,ESPECTRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535a416-ac8d-4a8b-9c4e-9ad79b165150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DIR = f'../msdb/data/hqtof/' # former: f'../msdb/data/hqtof/matrix/'\n",
    "Hqtof_CCMSIDs = list(np.load(os.path.join(DIR,'idlist/H_qtof_non-redundant_CCMSIDs.npy'))) # [CCMSID1,CCMSID2,CCMSID3, ...]\n",
    "GNPS_INFO = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a935c-c30f-4ac1-b4ac-4fc402e4335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calculate by update matchms package\n",
    "ALGO = 'modified_cosine'\n",
    "SPEC_SIM_MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGO}.npy')) # \n",
    "MP_MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/cosine_peak_matrix.npy')) # \n",
    "\n",
    "# SPEC1,SPECTRUM1 = get_spectra_from_einfo(GNPS_INFO,'CCMSLIB00000001547')\n",
    "# SPEC2,SPECTRUM2 = get_spectra_from_einfo(GNPS_INFO,'CCMSLIB00000001548')                                    \n",
    "# SPEC_SIM,MP = functions_new.clac_spec_sim(SPEC1,SPECTRUM1, SPEC2,SPECTRUM2,ALGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26736ebe-e134-45e5-8ed3-8bdf6cab91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \n",
    "DIR = f'../msdb/data/hqtof/' # former: f'../msdb/data/hqtof/matrix/'\n",
    "Hqtof_CCMSIDs = list(np.load(os.path.join(DIR,'idlist/H_qtof_non-redundant_CCMSIDs.npy'))) # [CCMSID1,CCMSID2,CCMSID3, ...]\n",
    "GNPS_INFO = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "MP_MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/cosine.npy')) # \n",
    "SPEC_SIM_MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/cosine.npy')) # \n",
    "\n",
    "# Calc \n",
    "ALGO = 'modified_cosine'\n",
    "for idx1 in trange(len(Hqtof_CCMSIDs)):\n",
    "    CCMSID1 = Hqtof_CCMSIDs[idx1]\n",
    "    SPEC1,SPECTRUM1 = get_spectra_from_einfo(GNPS_INFO,CCMSID1)\n",
    "\n",
    "    for idx2 in range(idx1):\n",
    "        CCMSID2 = Hqtof_CCMSIDs[idx2]\n",
    "        SPEC2,SPECTRUM2 = get_spectra_from_einfo(GNPS_INFO,CCMSID2)\n",
    "        if SPEC_SIM_MATRIX1[idx1,idx2] > 0:\n",
    "            SPEC_SIM,MP = functions_new.clac_spec_sim(SPEC1,SPECTRUM1, SPEC2,SPECTRUM2,ALGO)\n",
    "            SPEC_SIM_MATRIX1[idx1,idx2] = SPEC_SIM\n",
    "            SPEC_SIM_MATRIX1[idx2,idx1] = SPEC_SIM\n",
    "            MP_MATRIX1[idx1,idx2] = MP\n",
    "            MP_MATRIX1[idx2,idx1] = MP\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b623b931-bd1b-4806-86e2-747de8aa444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "# parse args\n",
    "# args = parse_args()\n",
    "# ALGORITHM = args.algorithm\n",
    "ALGORITHM = 'cosine'\n",
    "\n",
    "# Load processed json file\n",
    "GNPS_JSON = '../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json'\n",
    "with open(GNPS_JSON, 'r') as f:\n",
    "    gnps_info = json.load(f)\n",
    "\n",
    "# # Load filtered CCMSIDs\n",
    "# CCMSIDs = np.load('H_qtof_non-redundant_CCMSIDs.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4229e-4e95-4ca6-bf55-bdd8302465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate matrices\n",
    "# Create empty matrices\n",
    "similarity_matrix = np.zeros((len(CCMSIDs), (len(CCMSIDs))))\n",
    "peak_matrix = np.zeros((len(CCMSIDs), (len(CCMSIDs))))\n",
    "\n",
    "# Calculate by different algorithms\n",
    "for idx1 in trange(len(CCMSIDs)):\n",
    "    spec1, spectrum1 = functions_new.GNPS_info_format(gnps_info, CCMSIDs[idx1])\n",
    "    for idx2 in range(idx1):\n",
    "        spec2, spectrum2 = functions_new.GNPS_info_format(gnps_info, CCMSIDs[idx2])\n",
    "        if ALGORITHM == 'cosine':\n",
    "            try:\n",
    "                RESULT = peaktools.cosine(spectrum1, spectrum2, 0.05)\n",
    "                SIMILARITY = round(RESULT.score, 2)\n",
    "                N_PEAKS = RESULT.matches\n",
    "            except ZeroDivisionError:\n",
    "                SIMILARITY, N_PEAKS = 0, 0\n",
    "\n",
    "        if ALGORITHM == 'modified_cosine':\n",
    "            try:\n",
    "                RESULT = peaktools.modified_cosine(spectrum1, spectrum2, 0.05)\n",
    "                SIMILARITY = round(RESULT.score,2)\n",
    "                N_PEAKS = RESULT.matches\n",
    "            except ZeroDivisionError:\n",
    "                SIMILARITY, N_PEAKS = 0, 0\n",
    "\n",
    "        if ALGORITHM == 'neutral_loss':\n",
    "            try:\n",
    "                RESULT = peaktools.neutral_loss(spectrum1, spectrum2, 0.05)\n",
    "                SIMILARITY = round(RESULT.score, 2)\n",
    "                N_PEAKS = RESULT.matches\n",
    "            except ZeroDivisionError:\n",
    "                SIMILARITY, N_PEAKS = 0, 0\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                SIMILARITY = round(spectral_entropy.similarity(spec1, spec2, method=ALGORITHM, ms2_da=0.05), 2)\n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                SIMILARITY, N_PEAKS = 0, 0\n",
    "\n",
    "        similarity_matrix[idx1, idx2] = SIMILARITY\n",
    "        similarity_matrix[idx2, idx1] = SIMILARITY\n",
    "        peak_matrix[idx1, idx2] = N_PEAKS\n",
    "        peak_matrix[idx2, idx1] = N_PEAKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f93f1-47db-4adc-8afe-3c93af657e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save similarity matrices\n",
    "np.save(f'{ALGORITHM}_similarity_matrix.npy', similarity_matrix)\n",
    "np.save(f'{ALGORITHM}_peak_matrix.npy', peak_matrix)\n",
    "\n",
    "# Save dictinary (indices <str> : CCMSIDs)\n",
    "INDEXtoCCMSID = {index: CCMSID for index, CCMSID in enumerate(CCMSIDs)}\n",
    "with open (f'{ALGORITHM}_INDEXtoCCMS.json', 'w') as f2:\n",
    "    json.dump(INDEXtoCCMSID,f2)\n",
    "\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dda317-a3ee-4a0c-bff4-acb8db33c689",
   "metadata": {},
   "source": [
    "## Chemical similarity\n",
    "* Dice similarity, n_bits = 1024, radius = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9275f6f-d8f7-4e19-9fdb-9fefbec16a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FP database\n",
    "IDX2SMILE = []\n",
    "\n",
    "for idx, SPEC in tqdm(enumerate(Hqtof_CCMSIDs), total=len(Hqtof_CCMSIDs)):\n",
    "    CCMSID = Hqtof_CCMSIDs[idx]\n",
    "    SMILE = GNPS_INFO[CCMSID]['SMILE']\n",
    "    IDX2SMILE.append([SMILE, idx])\n",
    "\n",
    "FPDB = f'../msdb/data/hqtof/chem/hqtof_fp_db.h5'\n",
    "if not os.path.exists(FPDB):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE,\n",
    "        filename=FPDB,\n",
    "        mol_format='smiles',  # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843dad67-c2da-4a15-9ded-abef2fd7096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_SPECTRA search against FS_E_LIB\n",
    "fpe = FPSim2Engine(fp_filename=FPDB)\n",
    "hit_dict = {}\n",
    "for idx in trange(len(Hqtof_CCMSIDs)):\n",
    "    try:\n",
    "        CCMSID = Hqtof_CCMSIDs[idx]\n",
    "        SMILE = GNPS_INFO[CCMSID]['SMILE']\n",
    "        results = fpe.similarity(SMILE, threshold=0, metric='dice', n_workers=1)  # [(LIBidx,similarity1),(),...]\n",
    "        results = [x for x in results if x[0] != idx] # Remove self comparison\n",
    "        fpidx_list = [x[0] for x in results]\n",
    "        fpsim_list = [x[1] for x in results]\n",
    "\n",
    "        if fpidx_list:\n",
    "            hit_dict[idx] = {'idx': fpidx_list, 'sim_list': fpsim_list}  # {LIBidx: {},{},..}\n",
    "    except:print(idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4494a-60c2-4a8b-9ea8-fab924628964",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECHEM_MATRIX  = np.full((len(Hqtof_CCMSIDs),len(Hqtof_CCMSIDs)), 0.0, dtype=float) \n",
    "for key, value in hit_dict.items():\n",
    "    QueryIdx = key\n",
    "    MatchIdxs = value['idx']\n",
    "    MatchSim = value['sim_list']\n",
    "    for idx, MatchIdx in enumerate(MatchIdxs):\n",
    "        ECHEM_MATRIX[QueryIdx,MatchIdx] = MatchSim[idx]\n",
    "\n",
    "# Save results\n",
    "DIR = '../msdb/data/hqtof/chem/'\n",
    "np.save(os.path.join(DIR,f'hqtof_dice.npy'),ECHEM_MATRIX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f0b73-98a3-4041-ae95-aab387c2bd27",
   "metadata": {},
   "source": [
    "## Peak percentage similairty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f27ab7-4cb4-45d1-9e9a-ac509c138061",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_matrix = np.zeros((len(IDXtoCCMSID), (len(IDXtoCCMSID))))\n",
    "for idx1 in trange(len(IDXtoCCMSID)):\n",
    "    CCMSID = IDXtoCCMSID[str(idx1)]\n",
    "    spec,spectrum = functions_new.GNPS_info_format(gnps_info,CCMSID)\n",
    "    total_peaks = len(spec)\n",
    "    for idx2 in range(idx1):\n",
    "        n_peaks = N_PEAK_MATRIX[idx1,idx2]\n",
    "        try:\n",
    "            peak_percentage = n_peaks/total_peaks\n",
    "        except:peak_percentage = 0\n",
    "        peak_matrix[idx1,idx2]  = peak_percentage\n",
    "        peak_matrix[idx2, idx1] = peak_percentage\n",
    "np.save(f'../msdb/data/matrix/peak_percentage_similarity_matrix.npy', peak_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e7b30-c1ac-471d-be52-17940adab5d0",
   "metadata": {},
   "source": [
    "# Preprocess matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b4e28-b375-415e-8ebd-85c7217fcf17",
   "metadata": {},
   "source": [
    "## Structural matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d66e83-23f8-41bf-b408-b4a680b44c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gnps-library json\n",
    "gnps_info = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "# Load structural matrices\n",
    "TANIMOTO_MATRIX_FILE = '../msdb/data/matrix/tanimoto_similarity_matrix.npy'\n",
    "TANIMOTO_MATRIX_INDEX = '../msdb/data/matrix/tanimoto_INDEXtoCCMS.json'\n",
    "\n",
    "tanimoto_matrix = np.load(TANIMOTO_MATRIX_FILE)\n",
    "tanimoto_index_info = functions_new.json_load(TANIMOTO_MATRIX_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a901c6-2b2d-4140-b98b-28f508f8c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check structural matrix (if one-to-one)\n",
    "idx1,idx2 = 0,1\n",
    "\n",
    "SMILE1 = gnps_info[tanimoto_index_info[f'{idx1}']]['SMILE']\n",
    "SMILE2 = gnps_info[tanimoto_index_info[f'{idx2}']]['SMILE']\n",
    "\n",
    "morgen_generator = cheminfo_tools.get_morgan_generator()\n",
    "taniscore = TanimotoSimilarity(morgen_generator.GetFingerprint(Chem.MolFromSmiles(SMILE1))\n",
    "                               ,morgen_generator.GetFingerprint(Chem.MolFromSmiles(SMILE2)))\n",
    "\n",
    "tanimoto_matrix[idx1,idx2],taniscore "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d36db2-ba40-4117-8aa7-3f96c3289b20",
   "metadata": {},
   "source": [
    "## Spectral matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b49b55-cf10-4c53-bd31-d79feda410d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gnps-library json\n",
    "gnps_info = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "# Load spectral matrices\n",
    "ALGORITHM = 'cosine'\n",
    "spec_sim_matrix = np.load(f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy')\n",
    "n_peaks_matrix = np.load(f'../msdb/data/matrix/{ALGORITHM}_peak_matrix.npy')\n",
    "spec_index_info = functions_new.json_load(f'../msdb/data/matrix/{ALGORITHM}_INDEXtoCCMS.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6fcf3-5d4d-4c29-923e-dc721294e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check structural matrix (if one-to-one)\n",
    "idx1,idx2 = 0,1\n",
    "CCMSID1,CCMSID2 = IDXtoCCMSID[f'{idx1}'],IDXtoCCMSID[f'{idx2}']\n",
    "\n",
    "\n",
    "spec1,spectrum1 = functions_new.GNPS_info_format(GNPS_INFO,CCMSID1) \n",
    "spec2,spectrum2 = functions_new.GNPS_info_format(GNPS_INFO,CCMSID2)\n",
    "\n",
    "result = peaktools.cosine(spectrum1,spectrum2,0.05)\n",
    "# result.score, result.matches, spec_sim_matrix[idx1,idx2], n_peaks_matrix[idx1,idx2]\n",
    "\n",
    "result,result[0],result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1151b6-e657-4e5b-980d-f3ff3d495eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_packages import evaluation\n",
    "\n",
    "group1,group2,group3,group4 = evaluation.get_groups()\n",
    "for a in group1:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e440d7-50c5-44e2-83dc-2aa824f1dcc3",
   "metadata": {},
   "source": [
    "## Peak matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55618fb-9f01-4329-913b-8390b55f1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create peak percentage matrix\n",
    "ALGORITHM = 'modified_cosine'\n",
    "if ALGORITHM == 'neutral_loss':\n",
    "    N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_peak_matrix.npy'  # expect for modified_cosine and neutral_loss\n",
    "elif ALGORITHM == 'modified_cosine':\n",
    "    N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_peak_matrix.npy'\n",
    "else:\n",
    "    N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/cosine_peak_matrix.npy'\n",
    "N_PEAK_MATRIX = np.load(N_PEAK_MATRIX_FILE)\n",
    "\n",
    "CCMSID1 = IDXtoCCMSID[str(0)]\n",
    "SPEC1,SPECTRUM1 = functions_new.GNPS_info_format(GNPS_INFO,CCMSID1)\n",
    "\n",
    "SIM_MATRIX = np.zeros((len(N_PEAK_MATRIX), (len(N_PEAK_MATRIX))))\n",
    "for idx1 in trange(len(N_PEAK_MATRIX)):\n",
    "    CCMSID1 = IDXtoCCMSID[str(idx1)]\n",
    "    SPEC1,SPECTRUM1 = functions_new.GNPS_info_format(GNPS_INFO,CCMSID1)\n",
    "    N_PEAKs = len(SPEC1)\n",
    "    for idx2 in range(idx1):\n",
    "        SHARED_PEAKs = N_PEAK_MATRIX[idx1,idx2]\n",
    "        if N_PEAKs !=0:\n",
    "            percentage = round(SHARED_PEAKs/N_PEAKs,2)\n",
    "        else:\n",
    "            percentage = 0\n",
    "\n",
    "        SIM_MATRIX[idx1,idx2] = percentage\n",
    "        SIM_MATRIX[idx2,idx1] = percentage\n",
    "        \n",
    "np.save(f'../msdb/data/matrix/{ALGORITHM}MCS_similarity_matrix.npy', SIM_MATRIX)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f087-1e82-4923-844c-d6d1cc59ec61",
   "metadata": {},
   "source": [
    "# MS1 match matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aceea82-1148-4528-b43d-36bf5b2705e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNPS_INFO = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "CCMSIDs = np.load('../msdb/data/idlist/H_qtof_non-redundant_CCMSIDs.npy')\n",
    "\n",
    "\n",
    "MS1_MATCH_MATRIX = np.zeros((len(CCMSIDs), (len(CCMSIDs))))\n",
    "for idx1 in trange(len(CCMSIDs)):\n",
    "    CCMSID1 = CCMSIDs[idx1]\n",
    "    PM1 = float(GNPS_INFO[CCMSID1]['PEPMASS'])\n",
    "    for idx2 in range(idx1):\n",
    "        CCMSID2 = CCMSIDs[idx2]\n",
    "        PM2 = float(GNPS_INFO[CCMSID2]['PEPMASS'])\n",
    "        PPM = functions_new.calculate_ppm(PM1,PM2)\n",
    "        if PPM < 15:\n",
    "            MS1_MATCH_MATRIX[idx1,idx2] = 1\n",
    "            MS1_MATCH_MATRIX[idx2, idx1] = 1\n",
    "        else:\n",
    "            MS1_MATCH_MATRIX[idx1, idx2] = 0\n",
    "            MS1_MATCH_MATRIX[idx2, idx1] = 0\n",
    "\n",
    "np.save(f'../msdb/data/structural_matrix/MS1match_matrix.npy', MS1_MATCH_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6c16a-9d67-4ed9-86b3-264a6bf74621",
   "metadata": {},
   "source": [
    "# Network evaluation\n",
    "## Chemical similarity\n",
    "还是有ccms没有class，需要check一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b25db4-ac27-4406-9d8d-4fab13d0d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networking\n",
    "G = nx.MultiGraph()\n",
    "THRESHOLD = 0.7\n",
    "for idx1 in trange(len(IDXtoCCMSID)):\n",
    "    CCMSID = IDXtoCCMSID[f'{idx1}']\n",
    "    G.add_node(CCMSID)\n",
    "    # node_attr = {'pepmass': pm1}\n",
    "    # G.add_node(id1, **node_attr)  # add nodes and attributes\n",
    "    \n",
    "for idx1 in trange(len(IDXtoCCMSID)):\n",
    "    CCMSID1 = IDXtoCCMSID[str(idx1)]\n",
    "    for idx2 in range(idx1):\n",
    "        CCMSID2 = IDXtoCCMSID[str(idx2)]\n",
    "        sim = TANIMOTO_MATRIX [idx1,idx2]\n",
    "        if sim >= 0.7:\n",
    "            edge_attr = {'tanimoto_similarity': sim, 'edge_type': 'tanimoto'}\n",
    "            G.add_edge(CCMSID1, CCMSID2, **edge_attr)\n",
    "\n",
    "MN_output = f'../msdb/data/network/MN_tanimoto_{THRESHOLD}.graphml'\n",
    "nx.write_graphml(G, MN_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f27e82-f6b4-48ef-b971-b4c40c221100",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "还是有152 个nan和91个'',最后需要check一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d1131-8b17-4ba0-9cce-662c5956f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "N_SPECTRA = len(CCMSIDs)\n",
    "G = nx.read_graphml(TANIMOTO_GRAPHML_FILE)\n",
    "N_PAIRs = G.number_of_edges() # Tanimoto score >=0.7\n",
    "NPSUPERCLASSES = []\n",
    "for CCMSID in CCMSIDs:\n",
    "    try:\n",
    "        SUPERCLASS = GNPS_INFO[CCMSID]['np_classifier_superclass']\n",
    "        # print(SUPERCLASS)\n",
    "        NPSUPERCLASSES.append(SUPERCLASS)\n",
    "    except:pass\n",
    "     \n",
    "NPSUPERCLASSES_DICT = Counter(NPSUPERCLASSES)\n",
    "\n",
    "print(f'Total number of spectra and compounds: {N_SPECTRA}, number of high similar pairs: {N_PAIRs}')\n",
    "print(NPSUPERCLASSES_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bcd24-58a7-400d-b781-c8b2771b3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(IDXtoCCMSID)\n",
    "2572/2*2571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0512166-c052-49b3-9bbe-e642688b320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count positive (tanimoto score >= 0.7)\n",
    "POS_PAIRs = 0\n",
    "for idx1 in trange(len(IDXtoCCMSID)):\n",
    "    for idx2 in range(idx1):\n",
    "        TANIMOTO_SCORE = TANIMOTO_MATRIX[idx1,idx2]\n",
    "        if TANIMOTO_SCORE >= 0.7:\n",
    "            POS_PAIRs += 1\n",
    "\n",
    "print(f'There are {POS_PAIRs} positive pairs, accounting for {POS_PAIRs/3306306*100} total pairs.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f969183-8739-4d36-b993-31dd0aa140d6",
   "metadata": {},
   "source": [
    "## Network generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e89406-e4f3-4f5c-8bca-b41b1047cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Load gnps-library json\n",
    "gnps_info = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "# Load spectral similarity matrices\n",
    "N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/cosine_peak_matrix.npy' # expect for modified_cosine and neutral_loss\n",
    "N_PEAK_MATRIX = np.load(N_PEAK_MATRIX_FILE)\n",
    "\n",
    "# Load structural similarity matrices\n",
    "tanimoto_matrix = np.load(f'../msdb/data/matrix/tanimoto_similarity_matrix.npy')\n",
    "IDXtoCCMSID = functions_new.json_load('../msdb/data/structural_matrix/INDEXtoCCMS.json')\n",
    "CCMSIDtoIDX = {value:key for key,value in IDXtoCCMSID.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff19e1-d8f8-478d-95bf-4473b451db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any spectral algorithm missing, peak percentage can directly calculated by peak matrices\n",
    "group1,group2,group3,group4 = evaluation.get_groups()\n",
    "ALGORITHMs = group1 + group2 + group3 + group4 # get all the spectral algorithms\n",
    "\n",
    "MISSED_ALGORITHMs = []\n",
    "for algorithm in group:\n",
    "    file = f'../msdb/data/matrix/{algorithm}_similarity_matrix.npy'\n",
    "    if not os.path.exists(file):\n",
    "        MISSED_ALGORITHMs.append(algorithm)\n",
    "INTERSECTION_ALGORITHMs = list(set(ALGORITHMs) - set(MISSED_ALGORITHMs)) # Take the intersection\n",
    "MISSED_ALGORITHMs, len(ALGORITHMs), len(INTERSECTION_ALGORITHMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2e740-65be-4c2b-b5fa-5ad7c9aa8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Load gnps-library json\n",
    "gnps_info = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "# Load spectral similarity matrices\n",
    "N_PEAK_MATRIX_FILE = f'../msdb/data/matrix/cosine_peak_matrix.npy'  # expect for modified_cosine and neutral_loss\n",
    "N_PEAK_MATRIX = np.load(N_PEAK_MATRIX_FILE)\n",
    "\n",
    "# Load structural similarity matrices\n",
    "tanimoto_matrix = np.load(f'../msdb/data/matrix/tanimoto_similarity_matrix.npy')\n",
    "IDXtoCCMSID = functions_new.json_load('../msdb/data/structural_matrix/INDEXtoCCMS.json')\n",
    "CCMSIDtoIDX = {value: key for key, value in IDXtoCCMSID.items()}\n",
    "\n",
    "\n",
    "# Generate networks with various algorithm/spectral similarity/shared peaks\n",
    "SPEC_THRESHOLD = 0.7\n",
    "PEAK_THRESHOLD = 6\n",
    "\n",
    "# group1, group2, group3, group4 = evaluation.get_groups()\n",
    "# ALGORITHMs = group1 + group2 + group3 + group4 + ['peak_percentage'] # get all the spectral algorithms\n",
    "ALGORITHMs = ['modified_cosine']\n",
    "for ALGORITHM in tqdm(ALGORITHMs, total=len(ALGORITHMs)):\n",
    "    SPEC_SIM_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy'\n",
    "    SPEC_SIM_MATRIX = np.load(SPEC_SIM_MATRIX_FILE)\n",
    "\n",
    "    topology.refMN_generate(SPEC_THRESHOLD, PEAK_THRESHOLD, SPEC_SIM_MATRIX, IDXtoCCMSID, ALGORITHM, gnps_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf32ec-5cc7-46bb-9e25-9b77734ad8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the order of two index lists is the same\n",
    "info1 = functions_new.json_load('../msdb/data/structural_matrix/tanimoto_INDEXtoCCMS.json')\n",
    "info2 = functions_new.json_load('../msdb/data/structural_matrix/INDEXtoCCMS.json')\n",
    "info1 == info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346095a-fd65-440c-b93b-2f259f4fe63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the two calculations are the same \n",
    "# They are not same, why?\n",
    "ALGORITHM = 'penrose_size'\n",
    "SPEC_SIM_MATRIX_FILE0 = f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix0.npy'\n",
    "SPEC_SIM_MATRIX0 = np.load(SPEC_SIM_MATRIX_FILE)\n",
    "SPEC_SIM_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy'\n",
    "SPEC_SIM_MATRIX = np.load(SPEC_SIM_MATRIX_FILE)\n",
    "SPEC_SIM_MATRIX0 == SPEC_SIM_MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fcce46-21ed-4d9f-9ae9-0041a05b6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the matrices are calculated one-to-one by matrices\n",
    "# ALGORITHM = ALGORITHMs[2]\n",
    "\n",
    "idx1,idx2 = 333,35\n",
    "CCMSID1,CCMSID2 = IDXtoCCMSID[str(idx1)],IDXtoCCMSID[str(idx2)]\n",
    "SPEC1,SPECTRUM1 = functions_new.GNPS_info_format(gnps_info,CCMSID1)\n",
    "SPEC2,SPECTRUM2 = functions_new.GNPS_info_format(gnps_info,CCMSID2)\n",
    "\n",
    "\n",
    "for ALGORITHM in ['neutral_loss']:\n",
    "    try:\n",
    "        SPEC_SIM_MATRIX_FILE = f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy'\n",
    "        SPEC_SIM_MATRIX = np.load(SPEC_SIM_MATRIX_FILE)\n",
    "        if ALGORITHM == 'neutral_loss':\n",
    "            SIMILARITY = round(peak_tools.neutral_loss(SPECTRUM1, SPECTRUM2, 0.05), 2)\n",
    "            \n",
    "        else:\n",
    "            SIMILARITY = round(spectral_entropy.similarity(SPEC1, SPEC2, method=ALGORITHM, ms2_da=0.05), 2)\n",
    "        \n",
    "        if SIMILARITY !=  SPEC_SIM_MATRIX[idx1,idx2]:\n",
    "            print(ALGORITHM,SIMILARITY,SPEC_SIM_MATRIX[idx1,idx2])\n",
    "    except:print(ALGORITHM,SIMILARITY,SPEC_SIM_MATRIX[idx1,idx2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f180b-fad7-40fd-a8d2-4dd4c2b24655",
   "metadata": {},
   "source": [
    "### TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6b2d3-4ef9-4143-93bb-ad5ae70a62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "G1,G2,G3,G4 = evaluation.get_groups()\n",
    "ALGORITHMs = G1+G2+G3+G4+['peak_percentage']\n",
    "ALGORITHM = [a for a in ALGORITHMs if 'modified_cosine' in a][0]\n",
    "SPEC_THRESHOLD = 0.7\n",
    "PEAK_THRESHOLD = 6\n",
    "\n",
    "# Netwokr files\n",
    "GRAPHML_FILE = f'../msdb/data/network/MN_{ALGORITHM}_{SPEC_THRESHOLD}_{PEAK_THRESHOLD}.graphml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63145d9-1df9-42df-975b-a9e9be4cbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topK curating\n",
    "\n",
    "TOPK = 5\n",
    "def topK(GRAPHML_FILE,TOPK):\n",
    "    \n",
    "    G = nx.read_graphml(GRAPHML_FILE)\n",
    "    CLUSTERs = sorted([CLUSTER for CLUSTER in nx.connected_components(G) if len(CLUSTER) > 1],key = len, reverse=True)\n",
    "    for CLUSTER in CLUSTERs:\n",
    "        for NODEID in CLUSTER:\n",
    "            ADJ_NODEs = sorted(G[NODEID].items(),\n",
    "                               key = lambda item:item[1][f'{ALGORITHM}_similarity'], reverse=True) # Sort adjacenct nodes descending\n",
    "            ADJ_NODEIDs = [ADJ_NODE[0] for ADJ_NODE in ADJ_NODEs]\n",
    "            N_ADJ_NODEs = len(G[NODEID]) \n",
    "            if N_ADJ_NODEs > TOPK:\n",
    "                # 只保留前5条边\n",
    "                # TOP5_NODEs = ADJ_NODEs[:TOPK]\n",
    "                TOP5_NODEIDs = [ADJ_NODEID[0] for ADJ_NODEID in ADJ_NODEs[:TOPK]]\n",
    "                NODEstoRemove = set(ADJ_NODEIDs).symmetric_difference(set(TOP5_NODEIDs))\n",
    "                for NODEtoRemove in NODEstoRemove:\n",
    "                    G.remove_edge(NODEID,NODEtoRemove)\n",
    "                    \n",
    "    DIR, FILENAME = os.path.split(GRAPHML_FILE)\n",
    "    MN_OUTPUT = DIR+f'/{FILENAME.replace(\".graphml\",\"\")}_top{TOPK}.graphml'\n",
    "    nx.write_graphml(G, MN_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a649704-8b7e-40bd-a04e-5f23f8efd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N20 = evaluation.n20(MN_OUTPUT)\n",
    "NETWORK_ACC,CLUSTER_AVE_ACC,N_CLUSTER,N_CLUSTER_NODE = evaluation.network_accuracy(MN_OUTPUT, TANIMOTO_MATRIX_FILE, IDXtoCCMSID_FILE)\n",
    "RCCC = evaluation.ratio_of_correctly_classified_component(MN_OUTPUT,GNPS_LIBRARY_FILE)\n",
    "N20,NETWORK_ACC,RCCC,CLUSTER_AVE_ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ccaf4-a78e-4db5-97f4-7c9f618afc57",
   "metadata": {},
   "source": [
    "## Topology evaluation\n",
    "N20, network accuracy, correctly classified cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc7b9b-9844-478e-912c-e745fac7313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphml files\n",
    "TANIMOTO_MATRIX_FILE = '../msdb/data/structural_matrix/tanimoto_similarity_matrix.npy'\n",
    "IDXtoCCMSID_FILE = '../msdb/data/structural_matrix/tanimoto_INDEXtoCCMS.json'\n",
    "GNPS_INFO_FILE = '../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json'\n",
    "GNPS_LIBRARY_FILE = '../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json'\n",
    "\n",
    "\n",
    "SPEC_THRESHOLD = 0.7 # Thresholds\n",
    "PEAK_THRESHOLD = 6\n",
    "\n",
    "DIR = '../msdb/data/network/'\n",
    "GRAPHML_FILEs = [DIR+f for f in os.listdir(DIR) if 'MN' and f'{SPEC_THRESHOLD}' and f'{PEAK_THRESHOLD}' in f]\n",
    "gnps_info = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "# Evaluation\n",
    "N20 = evaluation.n20(GRAPHML_FILEs[0])\n",
    "NETWORK_ACC,CLUSTER_AVE_ACC,N_CLUSTER,N_CLUSTER_NODE = evaluation.network_accuracy(GRAPHML_FILEs[0], TANIMOTO_MATRIX_FILE, IDXtoCCMSID_FILE)\n",
    "RCCC = evaluation.ratio_of_correctly_classified_component(GRAPHML_FILEs[0],GNPS_LIBRARY_FILE)\n",
    "\n",
    "N20, NETWORK_ACC,RCCC,N_CLUSTER,N_CLUSTER_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f046496-843f-4c84-86a3-aefdceb3cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topology_evaluation\n",
    "# N20, network accuracy, correctly classified cluster\n",
    "g1,g2,g3,g4 = evaluation.get_groups()\n",
    "ALGORITHMs = g1+g2+g3+g4+['peak_percentage']\n",
    "\n",
    "SPEC_THRESHOLD = 0.7\n",
    "PEAK_THRESHOLD = 6\n",
    "ALGOs,N20s,NETWORK_ACCs,RCCCs,N_CLUSTERs,N_CLUSTER_NODEs= [],[],[],[],[],[]\n",
    "for ALGORITHM in tqdm(ALGORITHMs,total = len(ALGORITHMs)):\n",
    "    try:\n",
    "        GRAPHML_FILE = f'../msdb/data/network/MN_{ALGORITHM}_{SPEC_THRESHOLD}_{PEAK_THRESHOLD}.graphml'\n",
    "        N20 = evaluation.n20(GRAPHML_FILE)\n",
    "        NETWORK_ACC,CLUSTER_AVE_ACC,N_CLUSTER,N_CLUSTER_NODE = evaluation.network_accuracy(GRAPHML_FILE, TANIMOTO_MATRIX_FILE, IDXtoCCMSID_FILE)\n",
    "        RCCC = evaluation.ratio_of_correctly_classified_component(GRAPHML_FILE,GNPS_LIBRARY_FILE)\n",
    "        ALGOs.append(ALGORITHM)\n",
    "        N20s.append(N20)\n",
    "        NETWORK_ACCs.append(NETWORK_ACC)\n",
    "        N_CLUSTERs.append(N_CLUSTER)\n",
    "        N_CLUSTER_NODEs.append(N_CLUSTER_NODE)\n",
    "        RCCCs.append(RCCC)\n",
    "    except:\n",
    "        print(ALGORITHM)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ad32c-d93e-4f6d-a87f-bd14bc3b8c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save as pd.DataFrame\n",
    "df = pd.DataFrame({'Algorithm':ALGOs,\n",
    "                   'N20':N20s,\n",
    "                   'Network accuracy':NETWORK_ACCs,\n",
    "                   'N_cluster':N_CLUSTERs,\n",
    "                   'N_cluster_node':N_CLUSTER_NODEs\n",
    "                  })\n",
    "df.sort_values(by='Network accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb3b97-24f1-469c-abad-be0c7a0f3628",
   "metadata": {},
   "source": [
    "### Check MS2 comparison\n",
    "The performance of modified cosine is poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c312e21-a7e6-4523-99bd-d9f722457566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Parameters\n",
    "\n",
    "# Netwokr files\n",
    "GRAPHML_FILE = f'../msdb/data/network/MN_{ALGORITHM}_{SPEC_THRESHOLD}_{PEAK_THRESHOLD}.graphml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f76ec-b119-4902-9f68-20e0720e94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7f648-2685-46c6-8156-61c0107d922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check MS2 comparisons in clusters \n",
    "# Recognize clusters\n",
    "G = nx.read_graphml(GRAPHML_FILE)\n",
    "CLUSTERs = sorted([c for c in nx.connected_components(G) if len(c) > 1],key=len,reverse=True) # sort descending\n",
    "\n",
    "subgraph = G.subgraph(CLUSTERs[3])\n",
    "NODEIDs = list(subgraph.nodes())\n",
    "\n",
    "CCMSID1,CCMSID2 = NODEIDs[0],NODEIDs[1]\n",
    "for i in trange(len(NODEIDs)):\n",
    "    CCMSID1 = NODEIDs[i]\n",
    "    idx1 = int(CCMSIDtoIDX[CCMSID1])\n",
    "    for j in range(i):\n",
    "        CCMSID2 = NODEIDs[j]\n",
    "        idx2 = int(CCMSIDtoIDX[CCMSID2])\n",
    "        RESULT = functions_new.refms_compare(GNPS_INFO,ALGORITHM,CCMSID1,CCMSID2)\n",
    "        if ALGORITHM == 'modified_cosine' or ALGORITHM == 'neutral_loss':\n",
    "            if SPEC_SIM_MATRIX[idx1,idx2] == round(RESULT.score,2) and N_PEAK_MATRIX[idx1,idx2] == RESULT.matches:\n",
    "                pass\n",
    "            else: \n",
    "                print(ALGORITHM) \n",
    "                break\n",
    "\n",
    "        else:\n",
    "            if SPEC_SIM_MATRIX[idx1,idx2] == round(RESULT,2):\n",
    "                pass\n",
    "            else: \n",
    "                print(ALGORITHM) \n",
    "                break\n",
    "\n",
    "            \n",
    "# result,result.score,result.matches,SPEC_SIM_MATRIX[int(idx1),int(idx2)],N_PEAK_MATRIX[int(idx1),int(idx2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cae0a-a557-4c0a-b502-549be6755e33",
   "metadata": {},
   "source": [
    "# Algorithm evaluation\n",
    "TP, FP, TN, FN, ROC, FDR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fc52a-769f-43b8-bf79-022b71f5898f",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "Add class distribution\n",
    "In sklearn.metrices: TN:`C_{0,0}`, FN:`C_{1,0}`, TP: `C_{1,1}` and FP: `C_{0,1}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018b9e3-3963-46b2-ae47-597d384a1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and parameters\n",
    "# Parameters \n",
    "CHEM_THRESHOLD = 0.7\n",
    "SPEC_THRESHOLD = 0.7 # Thresholds\n",
    "PEAK_THRESHOLD = 6\n",
    "\n",
    "ALGORITHMs = G1 + G2 + G3 + G4 + ['peak_percentage'] \n",
    "# ALGORITHMs = ['peak_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880eb2c-68dd-447f-bf22-33fac8fb5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc51eb-5ce0-4a7d-94ab-1d07b08a7b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROC curve without shared peak matrix\n",
    "# Save roc_auc curve \n",
    "plt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "AUC_DICT = {}\n",
    "for ALGORITHM in tqdm(ALGORITHMs):\n",
    "    # try:\n",
    "        SPEC_SIM_MATRIX = np.load(f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy')\n",
    "        LABELs,SPEC_SIMILARITYs = [],[]\n",
    "        TEMP_INFO = {}\n",
    "        for idx1 in range(len(IDXtoCCMSID)):    \n",
    "            for idx2 in range(idx1):\n",
    "                CHEM_SIM = TANIMOTO_MATRIX[idx1,idx2]\n",
    "                SPEC_SIM = SPEC_SIM_MATRIX[idx1,idx2]\n",
    "                SPEC_SIMILARITYs.append(SPEC_SIM)\n",
    "                \n",
    "                if CHEM_SIM >= CHEM_THRESHOLD:\n",
    "                    LABELs.append(1)\n",
    "                else:\n",
    "                    LABELs.append(-1)\n",
    "                    \n",
    "        FPRs,TPRs, THRESHOLDs = roc_curve(LABELs, SPEC_SIMILARITYs)\n",
    "        AUC = auc(FPRs,TPRs)\n",
    "        YOUDEN = [TPRs[i] - FPRs[i] for i in range(len(THRESHOLDs))]\n",
    "        OPTIMAL_THRESHOLD = THRESHOLDs[YOUDEN.index(max(YOUDEN))] # Optimal threshold\n",
    "        AUC_DICT[f'{ALGORITHM}'] = {'AUC':AUC,'OT':OPTIMAL_THRESHOLD}\n",
    "        if ALGORITHM == 'modifeid_cosine':\n",
    "            plt.plot(FPRs, TPRs, color=\"red\",alpha = 0.7, lw= 1.5, label=f\"ROC curve (area = {AUC:.3f})\")\n",
    "        if ALGORITHM == 'entropy':\n",
    "            plt.plot(FPRs, TPRs, color=\"blue\",alpha = 0.7, lw = 1.5, label=f\"ROC curve (area = {AUC:.3f})\")            \n",
    "        else:\n",
    "            plt.plot(FPRs, TPRs, color=\"grey\",alpha = 0.7, lw = 0.8, label=f\"ROC curve (area = {AUC:.3f})\")\n",
    "    # except:print(ALGORITHM)\n",
    "        \n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\", fontname='Arial', fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontname='Arial', fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12,\n",
    "                labelfontfamily ='Arial', labelcolor='black', width=1, length=2)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.title(\"Receiver Operating Characteristic\")\n",
    "# plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "# plt.savefig(\"../msdb/data/pic/ROC_AUC.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.savefig(\"../msdb/data/pic/ROC_AUC.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "with open(\"../msdb/data/pic/ROC_AUC.json\",'w') as f: # Save ROC_AUC json\n",
    "    json.dump(AUC_DICT,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba1dd7-e491-4de9-b097-b6fe06b8dec8",
   "metadata": {},
   "source": [
    "### FDR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c14cc-5cb2-400b-b866-305dd505d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MS1MATCH = 0\n",
    "for idx1 in trange(len(IDXtoCCMSID)):    \n",
    "    for idx2 in range(idx1):\n",
    "        if MS1_MATCH_MATRIX[idx1,idx2] == 1:\n",
    "            N_MS1MATCH += 1 \n",
    "print(N_MS1MATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207fa85d-3cb8-4e81-b7b7-f2878c9f6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR v.s. similarity plotting\n",
    "FDR_DICT = {}\n",
    "for ALGORITHM in tqdm(['modified_cosine']):#tqdm(ALGORITHMs[:1]):\n",
    "    try:\n",
    "        SPEC_SIM_MATRIX = np.load(f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy')\n",
    "        LABELs,SPEC_SIMILARITYs = [],[]\n",
    "        TEMP_INFO = {}\n",
    "        for idx1 in range(len(IDXtoCCMSID)):    \n",
    "            for idx2 in range(idx1):\n",
    "                CHEM_SIM = TANIMOTO_MATRIX[idx1,idx2]\n",
    "                SPEC_SIM = SPEC_SIM_MATRIX[idx1,idx2]          \n",
    "                \n",
    "                SPEC_SIMILARITYs.append(SPEC_SIM)\n",
    "                if CHEM_SIM >= CHEM_THRESHOLD:\n",
    "                    LABELs.append(1)\n",
    "                else:\n",
    "                    LABELs.append(-1)\n",
    "                    \n",
    "        FPRs,TPRs, THRESHOLDs = roc_curve(LABELs, SPEC_SIMILARITYs)\n",
    "        FDRs = [] # Calculate FDR\n",
    "        for THRESHOLD in tqdm(THRESHOLDs,total=len(THRESHOLDs)):\n",
    "            Y_PREDCTIONs = []\n",
    "            for idx1 in range(len(IDXtoCCMSID)):\n",
    "                for idx2 in range(idx1):\n",
    "                    SPEC_SIM = SPEC_SIM_MATRIX[idx1,idx2]\n",
    "                    MS1_MATCH = MS1_MATCH_MATRIX[idx1,idx2]\n",
    "                    if SPEC_SIM >= THRESHOLD and MS1_MATCH == 1:\n",
    "                        Y_PREDCTIONs.append(1)\n",
    "                    else: \n",
    "                        Y_PREDCTIONs.append(-1)\n",
    "            CONFUSION_METRIX = confusion_matrix(LABELs, Y_PREDCTIONs)  \n",
    "            \n",
    "            TP,FP = CONFUSION_METRIX[1,1],CONFUSION_METRIX[0,1]\n",
    "            if (TP + FP) == 0:\n",
    "                FDRs.append(0) \n",
    "            else:\n",
    "                FDRs.append(FP/(TP+FP))\n",
    "\n",
    "        plt.plot(THRESHOLDs,FDRs,'b*-',label = f'ROC curve of {ALGORITHM}')\n",
    "    except:print(ALGORITHM)\n",
    "        \n",
    "# plt.plot([0,1],[0,1],'r--',label = '45° reference')\n",
    "plt.legend()\n",
    "plt.xlabel('Spectral similarity score')\n",
    "plt.ylabel('False-discovery rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fc531-bb50-4bb3-9a24-5deb3bf84438",
   "metadata": {},
   "source": [
    "### Spec sim heatmap hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760f88b-dbd0-446b-a685-b3a53f6b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectral similarity matrices\n",
    "G1,G2,G3 = evaluation.get_groups()\n",
    "TALGOs = G1 + G2\n",
    "TALGOs.remove('modified_cosine')\n",
    "\n",
    "# ALGORITHMs.insert(0, 'cosine')\n",
    "# ALGORITHMs.insert(0, 'modified_cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d15fb-9541-462b-9fa2-69a00bdd459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D hist\n",
    "DIR = f'../msdb/data/hqtof/SpecSimMatrix/'\n",
    "ALGORITHMs = ['cosine']\n",
    "for ALGO in ALGORITHMs:\n",
    "    plt.figure(figsize=(6, 1.2), constrained_layout=True)\n",
    "    \n",
    "    SIMILARITY = [] # Hist data    \n",
    "    SPEC_SIM_MATRIX = np.load(os.path.join(DIR,f'{ALGO}.npy'))\n",
    "    for idx1 in range(len(SPEC_SIM_MATRIX)):\n",
    "        for idx2 in range(idx1):\n",
    "            SIMILARITY.append(SPEC_SIM_MATRIX[idx1,idx2])\n",
    "    sns.kdeplot(\n",
    "        data=SIMILARITY,\n",
    "        # x=xlabel,\n",
    "        lw =0.5,\n",
    "        clip=(0, 1),\n",
    "        legend=True,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        bw_method= 0.2,\n",
    "        warn_singular=False\n",
    "        )\n",
    "    plt.axis('off')\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "    plt.savefig(f'../msdb/data/pic/hist/{ALGO}_hist.png', dpi=300, bbox_inches= 'tight',pad_inches=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1323dcd-7241-4f8d-9a48-80c9c362f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectral similarity matrices\n",
    "# Param\n",
    "\n",
    "DIR = f'../msdb/data/hqtof/' # former: f'../msdb/data/hqtof/matrix/'\n",
    "ALGORITHMs = ['modified_cosine']\n",
    "OTHERs = [a for a in TALGOs if a not in ALGORITHMs]\n",
    "OTHERs = ['cosine']\n",
    "BINs = 75\n",
    "\n",
    "for idx1 in range(len(OTHERs)):\n",
    "    ALGORITHM1 = OTHERs[idx1]\n",
    "    SPEC_SIM_MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM1}.npy'))\n",
    "    SIMILARITY1 = []\n",
    "    for i in range(len(SPEC_SIM_MATRIX1)):\n",
    "        for j in range(i):\n",
    "            SIMILARITY1.append(SPEC_SIM_MATRIX1[i,j])\n",
    "    \n",
    "    for idx2 in range(len(ALGORITHMs)):\n",
    "        ALGORITHM2 = ALGORITHMs[idx2]\n",
    "        SPEC_SIM_MATRIX2 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM2}.npy'))\n",
    "        SIMILARITY2 = []\n",
    "        for i in range(len(SPEC_SIM_MATRIX2)):\n",
    "            for j in range(i):\n",
    "                SIMILARITY2.append(SPEC_SIM_MATRIX2[i,j])\n",
    "                \n",
    "        \n",
    "        tick_locators = mticker.FixedLocator(np.arange(0, BINs + 1, BINs / 4))\n",
    "        tick_labels = np.asarray([f\"{a:.2f}\" for a in np.arange(0, 1.01, 0.25)])\n",
    "        \n",
    "        fig, axe = plt.subplots(constrained_layout=True,figsize=(6, 6))\n",
    "        \n",
    "        hist, _, _ = np.histogram2d(\n",
    "            SIMILARITY1, # X label\n",
    "            SIMILARITY2, # Y label\n",
    "            bins = BINs,\n",
    "            range=[[0, 1], [0, 1]],\n",
    "        )\n",
    "        hist /= len(SIMILARITY1)\n",
    "        heatmap = sns.heatmap(\n",
    "            np.rot90(hist),\n",
    "            vmin=0.0,\n",
    "            vmax=0.001,\n",
    "            cmap=\"viridis\",\n",
    "            cbar = i == 2,\n",
    "            cbar_ax = cbar_ax if i == 2 else None,\n",
    "            # cbar=True, # Legend \n",
    "            cbar_kws={\"format\": mticker.StrMethodFormatter(\"{x:.3%}\")},\n",
    "            square=True,\n",
    "            xticklabels=False,\n",
    "            yticklabels=False,\n",
    "            norm=LogNorm(vmax=0.001),\n",
    "            ax = axe\n",
    "        )\n",
    "        \n",
    "        # # axe.plot([0, hist.shape[0]], [hist.shape[0] , 0], color='red', linewidth=1,linestyle=\"--\")\n",
    "        axe.yaxis.set_major_locator(tick_locators)\n",
    "        axe.xaxis.set_major_locator(tick_locators)\n",
    "        axe.set_yticklabels(tick_labels[::-1]) # Reverse\n",
    "        axe.set_xticklabels(tick_labels)\n",
    "        axe.set_xlabel(ALGORITHM1, fontname='Arial', fontsize=12)\n",
    "        axe.set_ylabel(ALGORITHM2, fontname='Arial', fontsize=12)\n",
    "        \n",
    "        axe.tick_params(axis='both', which='major', labelsize=12, labelfontfamily ='Arial', width=1, length=5) # Font settings\n",
    "        # axe.xaxis.set_major_formatter(mticker.PercentFormatter())\n",
    "        for _, spine in heatmap.spines.items():\n",
    "            spine.set_visible(True)\n",
    "\n",
    "        \n",
    "        axe.plot(\n",
    "            [0, BINs], [BINs, 0], color=\"red\", linestyle=\"dashed\"\n",
    "        )\n",
    "        \n",
    "        sns.despine(ax=axe) # Remove top and right border\n",
    "        \n",
    "    \n",
    "        # 显示图形\n",
    "        # plt.show()\n",
    "        plt.savefig(os.path.join(DIR,f'2Dhist/{ALGORITHM2}Y_{ALGORITHM1}X_2Dhist.png'), dpi=500, bbox_inches= 'tight',pad_inches=0.5)\n",
    "        # plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0bba2-cc95-4c5f-9dbc-eac4cc49b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../msdb/data/hqtof/SpecSimMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea0a82-1f68-40b8-8432-b9f547739ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate specific \n",
    "DIR = '../msdb/data/hqtof/'\n",
    "ALGORITHM1 = 'modified_cosine'\n",
    "MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM1}.npy'))\n",
    "\n",
    "G1,G2,G3 = evaluation.get_groups()\n",
    "TAs = G1+G2+G3\n",
    "TAs = ['dot_product_reverse']\n",
    "for ALGORITHM2 in TAs:\n",
    "    # ALGORITHM2 = 'entropy' #ALGORITHMs[0]\n",
    "    MATRIX2 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM2}.npy'))\n",
    "    \n",
    "    mask = np.triu_indices_from(MATRIX1, k=0) # The upper triangle without diagonal\n",
    "    count = np.sum(MATRIX2[mask] > MATRIX1[mask]) # 比较 MATRIX2 > MATRIX1 的位置\n",
    "    \n",
    "    n = MATRIX1.shape[0]\n",
    "    upper_indices = np.triu_indices(n, k=0) # The upper triangle without diagonal\n",
    "    total_count = len(upper_indices[0])\n",
    "    \n",
    "    pp = round(count/total_count,2)*100\n",
    "    \n",
    "    print(f'{ALGORITHM2} socore higher than {ALGORITHM1} in {pp}% spectral pairs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb17ba1-8e9e-4770-acda-3a63c7bceb71",
   "metadata": {},
   "source": [
    "### Algorithm serious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fa2b1-edad-4d5f-be06-e81e2d42a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "['weighted_dot_product','dot_product_reverse','dot_product','neutral_loss','modified_cosine']\n",
    "['vicis_symmetric_chi_squared_3','probabilistic_symmetric_chi_squared','symmetric_chi_squared']\n",
    "['squared_euclidean','euclidean']\n",
    "['ms_for_id','ms_for_id_v1']\n",
    "['entropy','unweighted_entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8994e-d2fe-4aa8-8d08-acd3d7479b32",
   "metadata": {},
   "source": [
    "### Spec Chem distribution\n",
    "Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669a70f-5c6c-4761-9bb4-f0e5dd78a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1,G2,G3 = topology.get_groups()\n",
    "ALGOs = G1+G2+G3\n",
    "# ALGORITHM = [a for a in ALGORITHMs if 'modified_cosine' in a][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93038897-a394-4529-b950-0c5cf6d67d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load spec matrix\n",
    "DIR = '../msdb/data/hqtof/matrix/'\n",
    "ALGO = 'dice'\n",
    "for ALGO in tqdm(ALGOs,total=len(ALGOs)):\n",
    "    try:\n",
    "        ChemSimMat = np.load('../msdb/data/hqtof/chem/ChemSim.npy')\n",
    "        SpecSimMat = np.load(os.path.join(DIR,f'{ALGO}_similarity_matrix.npy'))\n",
    "        \n",
    "        # High sim pairs\n",
    "        HSIdx = [np.where(arr >=0.7) for arr in ChemSimMat] # [(),(),...] list containing tuples\n",
    "        HSSpecSim = [SpecSimMat[idx][HSIdx[idx]] for idx in range(len(HSIdx)) if HSIdx[idx][0].any()]\n",
    "        # HSChemSim = [ChemSimMat[idx][HSIdx[idx]] for idx in range(len(HSIdx)) if HSIdx[idx][0].any()] \n",
    "        \n",
    "        HS_values = np.concatenate(HSSpecSim)\n",
    "        \n",
    "        # Low sim pairs\n",
    "        LSIdx = [np.where((arr >= 0.1) & (arr < 0.35)) for arr in ECHEM_MATRIX] \n",
    "        LSSpecSim = [SpecSimMat[idx][LSIdx[idx]] for idx in range(len(LSIdx)) if LSIdx[idx][0].any()]\n",
    "        LSChemSim = [ChemSimMat[idx][LSIdx[idx]] for idx in range(len(LSIdx)) if LSIdx[idx][0].any()] \n",
    "        \n",
    "        LS_values = np.concatenate(LSSpecSim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        data_ls = pd.DataFrame({'Values': LS_values, 'Type': 'LS'})\n",
    "        data_hs = pd.DataFrame({'Values': HS_values, 'Type': 'HS'})\n",
    "        \n",
    "        # 创建一个共享 x 轴的双 y 轴图\n",
    "        fig, ax1 = plt.subplots(figsize=(3, 6))\n",
    "        \n",
    "        # 绘制 LS_values 的小提琴图\n",
    "        sns.violinplot(x='Type', y='Values', data=data_ls, ax=ax1, color='blue', width=0.5,inner=None)\n",
    "        ax1.set_title(f\"{ALGO}\")\n",
    "        ax1.set_ylabel(\"LS Values\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        # 隐藏 ax1 的边框\n",
    "        for spine in ax1.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        ax1.xaxis.set_ticks_position('none')  # 隐藏 x 轴刻度\n",
    "        ax1.yaxis.set_ticks_position('none')  # 隐藏 y 轴刻度\n",
    "        \n",
    "        ax2 = ax1.twinx() # 创建第二个 y 轴\n",
    "        \n",
    "        ax2.spines['right'].set_position(('outward', -3)) # 调整 ax2 的位置，使其更靠近 ax1\n",
    "        \n",
    "        # 绘制 HS_values 的小提琴图\n",
    "        sns.violinplot(x='Type', y='Values', data=data_hs, ax=ax2, color='red', width=0.5,inner=None)\n",
    "        ax2.set_ylabel(\"HS Values\", color='red')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        \n",
    "        # 隐藏 ax2 的边框\n",
    "        for spine in ax2.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        \n",
    "        # 调整布局\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../msdb/data/hqtof/pic_violin/{ALGO}.png', dpi=500, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    except:print(ALGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f897d07-2d84-4ef8-a985-cf185056efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "print(FS_SPECTRA[1]['smile'])\n",
    "print(FS_SPECTRA[113]['smile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edd9fa-c07b-4fd3-928a-4afe8a3b8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_SPECTRA[113]['peaks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a80ba1-1e4e-4b22-8c93-f4391398fc3c",
   "metadata": {},
   "source": [
    "## Detailed inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c33f5-38e8-4ffc-a533-5b74b5f8de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clac_spec_sim(SPEC1,SPECTRUM1,SPEC2,SPECTRUM2,ALGO):\n",
    "    ''''''\n",
    "    cosine = CosineGreedy(tolerance=0.05)\n",
    "    neutral_loss = NeutralLossesCosine(tolerance=0.05)\n",
    "    modified_cosine = ModifiedCosine(tolerance=0.05)\n",
    "\n",
    "    if ALGO == 'modified_cosine':\n",
    "        score = modified_cosine.pair(SPECTRUM1, SPECTRUM2)\n",
    "        SPEC_SIM = score['score'].item()\n",
    "        N_PEAK = score['matches'].item()\n",
    "\n",
    "    elif ALGO == 'cosine':\n",
    "        score = cosine.pair(SPECTRUM1, SPECTRUM2)\n",
    "        SPEC_SIM = score['score'].item()\n",
    "        N_PEAK = score['matches'].item()\n",
    "\n",
    "    elif ALGO == 'neutral_loss':\n",
    "        score = neutral_loss.pair(SPECTRUM1, SPECTRUM2)\n",
    "        SPEC_SIM = score['score'].item()\n",
    "        N_PEAK = score['matches'].item()\n",
    "\n",
    "    elif ALGO == 'peak_percentage':\n",
    "        score = cosine.pair(SPECTRUM1, SPECTRUM2)\n",
    "        N_PEAK = score['matches'].item()\n",
    "        SPEC_SIM = N_PEAK / min(len(SPEC1), len(SPEC2))\n",
    "\n",
    "    else:\n",
    "        score = cosine.pair(SPECTRUM1, SPECTRUM2)\n",
    "        N_PEAK = score['matches'].item()\n",
    "        SPEC_SIM = similarity(SPEC1, SPEC2, method=ALGO, ms2_da=0.05)\n",
    "\n",
    "    return SPEC_SIM,N_PEAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21b1ed-089e-4718-8c52-534a25235d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "['weighted_dot_product','dot_product_reverse','dot_product','neutral_loss','modified_cosine']\n",
    "['vicis_symmetric_chi_squared_3','probabilistic_symmetric_chi_squared','symmetric_chi_squared']\n",
    "['squared_euclidean','euclidean']\n",
    "['ms_for_id','ms_for_id_v1']\n",
    "['entropy','unweighted_entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2231ef-a045-401e-b0f5-db2aa604b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hqtof_CCMSIDs = list(np.load('../msdb/data/hqtof/idlist/H_qtof_non-redundant_CCMSIDs.npy'))\n",
    "# Load processed json file\n",
    "GNPS_INFO = functions_new.json_load('../msdb/GNPSLIBRARY_250514/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "modified_cosine = ModifiedCosine(tolerance = 0.05)\n",
    "neutral_loss = NeutralLossesCosine(tolerance = 0.05)\n",
    "cosine = CosineGreedy(tolerance=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546deb8d-eb91-4ae9-9323-ace4f532eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = {'modified_cosine': 0.72, 'weighted_dot_product': 0.89, 'hellinger': 0.18, 'ms_for_id': 0.205, 'manhattan': 0.535,\n",
    "            'absolute_value': 0.535, 'intersection': 0.535, 'lorentzian': 0.52, 'ruzicka': 0.365, 'motyka': 0.535, 'fidelity': 0.72,\n",
    "            'bhattacharya_2': 0.755, 'matusita': 0.475, 'bhattacharya_1': 0.765, 'squared_chord': 0.72, 'vicis_symmetric_chi_squared_3': 0.625,\n",
    "            'probabilistic_symmetric_chi_squared': 0.67, 'harmonic_mean': 0.67, 'unweighted_entropy': 0.700, 'improved_similarity': 0.515,\n",
    "            'clark': 0.515, 'spectral_contrast_angle': 0.72, 'pearson_correlation': 0.845, 'dot_product': 0.72, 'inner_product': 0.1,\n",
    "            'whittaker_index_of_association': 0.11, 'dot_product_reverse': 0.99, 'avg_l': 0.175, 'entropy': 0.535, 'roberts': 0.285,\n",
    "            'baroni_urbani_buser': 0.735, 'neutral_loss': 0.72, 'jaccard': 0.54, 'dice': 0.52, 'peak_percentage': 0.71, 'squared_euclidean': 0.975,\n",
    "            'euclidean': 0.84, 'penrose_shape': 0.84, 'chebyshev': 0.885, 'ms_for_id_v1': 0.98, 'canberra': 0.055, 'divergence': 0.03, 'wave_hedges': 0.055,\n",
    "            'penrose_size': 0.23, 'mean_character': 0.985, 'symmetric_chi_squared': 0.950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9318b33-53aa-4c8d-82e9-fd98fcdf06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../msdb/data/hqtof'\n",
    "ALGORITHM1 = 'modified_cosine'\n",
    "MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM1}.npy'))\n",
    "\n",
    "ALGORITHM2 = 'bhattacharya_1'\n",
    "MATRIX2 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM2}.npy'))\n",
    "\n",
    "ChemSimMat = np.load(os.path.join(DIR,f'chem/hqtof_dice.npy'))\n",
    "\n",
    "# Get higher\n",
    "i, j = np.triu_indices_from(MATRIX1, k=1)  # The upper triangle without diagonal\n",
    "mask_condition = MATRIX2[i, j] > MATRIX1[i, j]\n",
    "indices = (i[mask_condition], j[mask_condition])\n",
    "pair_indices = list(zip(indices[0],indices[1]))\n",
    "\n",
    "\n",
    "TPs, FPs, TNs, FNs = [],[],[],[]\n",
    "for i in tqdm(pair_indices,total = len(pair_indices)):\n",
    "    idx1,idx2 = i\n",
    "    SIM1 = MATRIX1[idx1,idx2]\n",
    "    SIM2 = MATRIX2[idx1,idx2]\n",
    "    diff = abs(SIM1-SIM2)\n",
    "    ChemSim = ChemSimMat[idx1,idx2]\n",
    "    OT = optimal_threshold[ALGORITHM2]\n",
    "    if diff > 0.3:\n",
    "        if SIM1 > 0 and SIM2 >= OT and ChemSim >=0.75:\n",
    "            TPs.append(i)\n",
    "        elif SIM1 > 0 and SIM2 >= OT and ChemSim < 0.75:\n",
    "            FPs.append(i)\n",
    "            \n",
    "        elif SIM1 > 0 and SIM2 < OT and ChemSim >= 0.75:\n",
    "            FNs.append(i)\n",
    "        elif SIM1 > 0 and SIM2 < OT and ChemSim < 0.75:\n",
    "            TNs.append(i)\n",
    "len(TPs),len(FPs),len(TNs),len(FNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d156e7-890d-4cca-889a-c7cfbbf30a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIR = TPs[0]\n",
    "idx1, idx2 = PAIR[0],PAIR[1]\n",
    "CCMSID1,CCMSID2 = Hqtof_CCMSIDs[idx1], Hqtof_CCMSIDs[idx2]\n",
    "SPEC1, SPECTRUM1 = functions_new.gnps_info_format(GNPS_INFO,CCMSID1)\n",
    "SPEC2, SPECTRUM2 = functions_new.gnps_info_format(GNPS_INFO,CCMSID2)\n",
    "SIM1,MP1 = clac_spec_sim(SPEC1, SPECTRUM1,SPEC2, SPECTRUM2,ALGORITHM1)\n",
    "SIM2,MP2 = clac_spec_sim(SPEC1, SPECTRUM1,SPEC2, SPECTRUM2, ALGORITHM2)\n",
    "PM1, PM2 = float(GNPS_INFO[CCMSID1][\"PEPMASS\"]),float(GNPS_INFO[CCMSID2][\"PEPMASS\"])\n",
    "print(f'Top {CCMSID1}, precursor {PM1}')\n",
    "print(f'Bottom {CCMSID2}, precursor {PM2}')\n",
    "print(f\"Re-calced {ALGORITHM1}:{round(SIM1,2)}\",f\"{ALGORITHM2}: {round(SIM2,2)}\")\n",
    "\n",
    "SMILE1 = GNPS_INFO[CCMSID1]['SMILE']\n",
    "SMILE2 = GNPS_INFO[CCMSID2]['SMILE']\n",
    "print(f'Matched peaks',MP,MP2,f'Chemical dice {round(cheminfo_tools.dice(SMILE1,SMILE2),2)}')\n",
    "print(CCMSID1,MATRIX1[idx1,idx2], CCMSID2,MATRIX2[idx1,idx2]) # \n",
    "\n",
    "print(f\"{SMILE1}\\n{SMILE2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcde72-0682-45bb-8871-e7cf75c12d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To output spectra\n",
    "SPEC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa9b06-c1d7-4d09-87e1-e926f2e7c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To output matched peaks and scored by scripts\n",
    "spectrum_1 = sus.MsmsSpectrum(identifier='1', \n",
    "                              precursor_mz=PM1, \n",
    "                              precursor_charge=1,\n",
    "                              mz=np.array(SPEC1[:, 0],dtype=np.float64),\n",
    "                              intensity=np.array(SPEC1[:, 1],dtype=np.float64))\n",
    "spectrum_2 = sus.MsmsSpectrum(identifier='2', \n",
    "                              precursor_mz=PM2, \n",
    "                              precursor_charge=1,\n",
    "                              mz=np.array(SPEC2[:, 0],dtype=np.float64),\n",
    "                              intensity=np.array(SPEC2[:, 1],dtype=np.float64)) \n",
    "MCS_RES = peaktools.modified_cosine(spectrum_1,spectrum_2,0.1)\n",
    "NL_RES = peaktools.neutral_loss(spectrum_1,spectrum_2,0.1)\n",
    "MCS_RES,NL_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684d8a5-6537-4aa0-b5cb-9e0faff3a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCS matched peaks and its indices\n",
    "matched_indices = MCS_RES.matched_indices\n",
    "matched_indices_other = MCS_RES.matched_indices_other\n",
    "print(f'Shared peaks of mcs in spectrum1:{spectrum_1.mz[matched_indices]}')\n",
    "print(f'Shared peaks of mcs in spectrum2:{spectrum_2.mz[matched_indices]}')\n",
    "\n",
    "# NL shared peaks and its indices\n",
    "nl_spectrum_1 = peaktools.spec_to_neutral_loss(spectrum_1)\n",
    "nl_spectrum_2 = peaktools.spec_to_neutral_loss(spectrum_2)\n",
    "nl_matched_indices = NL_RES.matched_indices\n",
    "nl_matched_indices_other = NL_RES.matched_indices_other\n",
    "PM1-PM2,nl_spectrum_1.mz[nl_matched_indices],nl_spectrum_2.mz[nl_matched_indices_other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9a646-1ac4-40ed-ab42-72f7405aae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_spectrum = nl_spectrum_2\n",
    "np.column_stack((nl_spectrum.mz,nl_spectrum.intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbaee71-fe5e-4358-aea4-4e6488cae8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matchms v\n",
    "score1 = modified_cosine.pair(SPECTRUM1,SPECTRUM2)\n",
    "score2 = neutral_loss.pair(SPECTRUM1,SPECTRUM2)\n",
    "score1,score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b2bcc-af26-48a3-9556-f8420b19c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC1,SPEC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae85222-504d-4ae6-af59-60943b6f9021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
