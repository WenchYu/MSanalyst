{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbacfff-7b98-4ce3-8a1b-6fe9ad2d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook records related code for the 3 million spectral pairs derived from 2571 curated spectra\n",
    "# Here is a diagram showing the relative paths of the input and output files and folders\n",
    "# We provide compressed files in three folders: notebook, src, and msdb, at https://zenodo.org/uploads/17065209\n",
    "# Most input and output files are included except for some very large files, exceeding 20 GB, like the pairwise similarity matrix of each in-silico library.\n",
    "# Before using these codes, make sure to use them in the msanalyst folder cloned from git.\n",
    "'''\n",
    "MSanalyst/\n",
    "    ├── notebook/\n",
    "    ├── src/\n",
    "    └── msdb/\n",
    "        ├── GNPSLIBRARY/\n",
    "        |   ├── ALL_GNPS_NO_PROPOGATED.mgf  (input)\n",
    "        |   ├── GNPS-LIBRARY.mgf  (input)\n",
    "        |   ├── edbMS1.csv  (output)\n",
    "        |   ├── edb_info.json  (output)\n",
    "        |   ├── GNPS-LIBRARY-INFO.json  (output)\n",
    "        |   ├── GNPS-LIBRARY-INFO_new.json  (output)\n",
    "        |   └── FS_edb_smi.json  (input)\n",
    "        ├── GNPSLIBRARY_250514/\n",
    "        |   └── ALL_GNPS_NO_PROPOGATED.mgf  (input)\n",
    "        ├── COCONUT_2506/\n",
    "        |   ├── coconut_csv_lite-06-2025.csv  (input)\n",
    "        |   └── COCONUT.json  (output)\n",
    "        ├── data/\n",
    "        |   ├── hqtof/\n",
    "        |   |   ├── idlist/\n",
    "        |   |   |   └── H_qtof_non-redundant_CCMSIDs.npy  (output)\n",
    "        |   |   └── FS_hqtof.json  (output)\n",
    "        |   └── idlist/\n",
    "        |       ├── NpclasstoSupplement.npy  (output)\n",
    "        |       ├── NpclasstoSupplement.csv  (output)\n",
    "        |       └── NpclasstoSupplement.json  (output)\n",
    "        ├── FS_isdb_e0.json  (output)\n",
    "        ├── FS_isdb_e1.json  (output)\n",
    "        ├── FS_isdb_e2.json  (output)\n",
    "        └── isdb_info.json  (input)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2c360-0514-4a21-8e6c-62665b68b16d",
   "metadata": {},
   "source": [
    "# Import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc3bdf5-84a7-441b-939d-ad44fe86c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "import sys,os,json,spectral_entropy,sys,time\n",
    "sys.argv = ['jupyter']  # Clear the parameters passed to Jupyter\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spectrum_utils.spectrum as sus\n",
    "from spectral_entropy.spectral_entropy import calculate_entropy\n",
    "from my_packages import peaktools, functions_new, cheminfo_tools, evaluation\n",
    "from matplotlib.colors import LogNorm\n",
    "from matchms.importing import load_from_mgf\n",
    "from tqdm import tqdm, trange\n",
    "from ms_entropy import FlashEntropySearch\n",
    "from sklearn.metrics import roc_curve,auc,confusion_matrix\n",
    "from FPSim2.io import create_db_file\n",
    "from FPSim2 import FPSim2Engine\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.decomposition import PCA\n",
    "from matchms import Spectrum\n",
    "from matchms.similarity import ModifiedCosine,NeutralLossesCosine,CosineGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1b85c-1e6e-45f8-8f15-685ec977fbda",
   "metadata": {},
   "source": [
    "# Load library files\n",
    "## EDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4f127-9a62-434e-9cdb-780f445c343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GNPS library file\n",
    "t = time.time() \n",
    "\n",
    "# GNPS_FILE = '../msdb/GNPSLIBRARY/ALL_GNPS_NO_PROPOGATED.mgf'\n",
    "GNPS_CLEAN_FILE = '../msdb/GNPSLIBRARY/ALL_GNPS_cleaned.mgf'\n",
    "# GNPS_DEMO_FILE = '../msdb/GNPSLIBRARY/GNPS-LIBRARY-demo.mgf'\n",
    "\n",
    "# GNPS_INFO = list(load_from_mgf(GNPS_FILE))\n",
    "GNPS_CLAEN_INFO = list(load_from_mgf(GNPS_CLEAN_FILE))\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201c9bf-a16a-4482-bab5-5ac8a4a06500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library spectral file\n",
    "t = time.time()\n",
    "\n",
    "# ISMS1_CSV = '../msdb/isdbMS1.csv' # 'id', 'formula', 'exactmass', 'smiles', 'inchi', 'inchikey', 'm+h','m+nh4', 'm+na'\n",
    "# ISMS1_DF = pd.read_csv(ISMS1_CSV,low_memory=False)\n",
    "# EMS1_CSV = '../msdb/edbMS1.csv' # 'id', 'pepmass', 'smiles'\n",
    "# EMS1_DF = pd.read_csv(EMS1_CSV)\n",
    "\n",
    "# Flash search - Load\n",
    "FS_E_LIBRARY = functions_new.json_load('../msdb/FS_edb_info.json')\n",
    "e_search = FlashEntropySearch()\n",
    "FS_E_LIBRARY = e_search.build_index(FS_E_LIBRARY)\n",
    "\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7439fc-526e-4f98-af70-dfa8d6ff027b",
   "metadata": {},
   "source": [
    "## ISDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c086fe-5f8b-4f16-8d90-db66512fdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB energy 10,20,40\n",
    "ISDB_INFO = functions_new.json_load('../msdb/isdb_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f98696-a071-475c-9c0a-d188bfc1c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB energy = 10\n",
    "t = time.time()\n",
    "FS_IS_LIBRARY_e0 = functions_new.json_load('../msdb/FS_isdb_e0.json')\n",
    "is0_search = FlashEntropySearch()\n",
    "FS_IS0_LIBRARY = is0_search.build_index(FS_IS_LIBRARY_e0)\n",
    "\n",
    "# ISDB energy = 20\n",
    "t = time.time()\n",
    "FS_IS_LIBRARY_e1 = functions_new.json_load('../msdb/FS_isdb_e1.json')\n",
    "is1_search = FlashEntropySearch()\n",
    "FS_IS1_LIBRARY = is1_search.build_index(FS_IS_LIBRARY_e1)\n",
    "\n",
    "# ISDB energy = 40\n",
    "t = time.time()\n",
    "FS_IS_LIBRARY_e2 = functions_new.json_load('../msdb/FS_isdb_e2.json')\n",
    "is2_search = FlashEntropySearch()\n",
    "FS_IS2_LIBRARY = is2_search.build_index(FS_IS_LIBRARY_e2)\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e7187-5e7e-4056-95fb-90e6ee156b40",
   "metadata": {},
   "source": [
    "## Information supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c04d1-b507-4410-a637-dd0975f9c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplement the library with additional information (e.g., entropy, n_peaks, classes)\n",
    "# Param: FS_E_LIBRARY,FS_IS0_LIBRARY,FS_IS1_LIBRARY,FS_IS2_LIBRARY,\n",
    "# Return: LIBRARIES with supplemented information \n",
    "for SPECTRUM in tqdm(FS_E_LIBRARY, total = len(FS_E_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd6bcc-a4cb-4c17-9fdf-21d50eb1a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for SPECTRUM in tqdm(FS_IS0_LIBRARY, total = len(FS_IS0_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    SPECTRUM['peaks'] = PEAKs.tolist()\n",
    "    \n",
    "for SPECTRUM in tqdm(FS_IS1_LIBRARY, total = len(FS_IS1_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    SPECTRUM['peaks'] = PEAKs.tolist()\n",
    "\n",
    "for SPECTRUM in tqdm(FS_IS2_LIBRARY, total = len(FS_IS2_LIBRARY)):\n",
    "    PEAKs = SPECTRUM['peaks']\n",
    "    SPECTRUM['n_peak'] = len(PEAKs)\n",
    "    SPECTRUM['entropy'] = calculate_entropy(PEAKs)\n",
    "    SPECTRUM['peaks'] = PEAKs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5fc2a-9bac-4da0-a8f4-691aadd78c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../msdb/FS_isdb_e0.json', \"w\") as f:\n",
    "    json.dump(FS_IS0_LIBRARY, f)\n",
    "\n",
    "with open('../msdb/FS_isdb_e1.json', \"w\") as f:\n",
    "    json.dump(FS_IS1_LIBRARY, f)\n",
    "\n",
    "with open('../msdb/FS_isdb_e2.json', \"w\") as f:\n",
    "    json.dump(FS_IS2_LIBRARY, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16071f8e-bc49-48fb-864b-6ebe49df124b",
   "metadata": {},
   "source": [
    "## Hqtof lib Data for Figure 3H-I\n",
    "\n",
    "  \n",
    "Since spectra have different adduct types,sourced from redundant structures and different instrument platforms\n",
    "It is necessary to remove the influences mentioned above before evaluating the spectral similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b896f-2d8d-4ac1-b7f4-6e1c64783803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hqtof data\n",
    "GNPS_SPECTRA = functions_new.load_spectra_from_file('../msdb/GNPSLIBRARY/GNPS-LIBRARY.mgf')\n",
    "Hqtof_CCMSIDs = list(np.load('../msdb/data/hqtof/idlist/H_qtof_non-redundant_CCMSIDs.npy'))\n",
    "\n",
    "FS_SPECTRA = []\n",
    "for SPECTRUM in tqdm(GNPS_SPECTRA,total = len(GNPS_SPECTRA)):\n",
    "    CCMSID = SPECTRUM.metadata['spectrum_id']\n",
    "    if CCMSID in Hqtof_CCMSIDs:\n",
    "        PM = SPECTRUM.metadata['precursor_mz']\n",
    "        IONMODE = SPECTRUM.metadata['ionmode']\n",
    "        try:\n",
    "            SMILE = SPECTRUM.metadata['smiles']\n",
    "        except:\n",
    "            SMILE = GNPS_INFO[CCMSID]['CANONSMILES']\n",
    "            \n",
    "        CHARGE = SPECTRUM.metadata['charge']\n",
    "        SCLASS = GNPS_INFO[CCMSID]['np_classifier_superclass']\n",
    "        \n",
    "        peaks = np.column_stack((SPECTRUM.mz,SPECTRUM.intensities))\n",
    "        # peaks = se.clean_spectrum(peaks, max_mz=PM + 1.6)\n",
    "        FS_SPECTRA.append({\n",
    "            \"id\": CCMSID,\n",
    "            \"precursor_mz\": PM,\n",
    "            \"peaks\": peaks.tolist(),\n",
    "            \"smile\": SMILE,\n",
    "            \"charge\": CHARGE,\n",
    "            \"ion_mode\":IONMODE,\n",
    "            'superclass':[SCLASS]\n",
    "            })\n",
    "\n",
    "# Save\n",
    "sorted_list = sorted(FS_SPECTRA, key=lambda x: x['precursor_mz'])\n",
    "FS_GNPS_LIBRARY_OUTPUT = '../msdb/data/hqtof/FS_hqtof.json'\n",
    "with open(FS_GNPS_LIBRARY_OUTPUT, \"w\") as f:\n",
    "    json.dump(sorted_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee5fc8f-20ac-4777-b5a5-95c89ce5fcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load hqtof data\n",
    "HQTOF = functions_new.json_load('../msdb/data/hqtof/FS_hqtof.json')\n",
    "# hqtof_search = FlashEntropySearch()\n",
    "# FS_SPECTRA = hqtof_search.build_index(HQTOF) # Pre-clean and sorted flash spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a78d0-bb54-4ceb-9e73-0756db195f5d",
   "metadata": {},
   "source": [
    "# Figure S1 Kdeplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28506678-81c5-423a-95d1-d2dab27691ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 3.5\n",
    "height = width / 1.618\n",
    "# To take an overview of the ISDB and EDB\n",
    "# Param: FS_E_LIBRARY,FS_IS0_LIBRARY,FS_IS1_LIBRARY,FS_IS2_LIBRARY,\n",
    "# Return: kdeplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa625d7e-9b77-4b7a-8e4d-f247289c0ce8",
   "metadata": {},
   "source": [
    "## EDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48684b-d876-437a-9a40-b522bffd34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "E_pm,E_npeak,E_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_E_LIBRARY,total = len(FS_E_LIBRARY)):\n",
    "    E_pm.append(SPECTRUM['precursor_mz'])\n",
    "    E_npeak.append(SPECTRUM['n_peak'])\n",
    "    E_entropy.append(SPECTRUM['entropy'])\n",
    "E_DF = pd.DataFrame({\n",
    "    'entropy': E_entropy,\n",
    "    'PM': E_pm,\n",
    "    'NPEAK':E_npeak\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc9063-b51f-468e-8227-65057717d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample\n",
    "sample_size = 50000  # Randomly select one-tenth of the entire library\n",
    "sample_df = E_DF.sample(n=sample_size)\n",
    "\n",
    "plt.figure(figsize=(width * 2, height * 2))\n",
    "kde = sns.kdeplot(\n",
    "    data=sample_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    # cut=0,\n",
    "    cbar=True,\n",
    "    legend=False,\n",
    "    color = '#E84445'\n",
    ")\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/E_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c25b7-55a7-4054-8bb0-3b64c61835ba",
   "metadata": {},
   "source": [
    "## ISDB_e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee690e9-54ce-4204-ba64-cbd88cf8794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB_e0\n",
    "t = time.time()\n",
    "IS0_pm,IS0_npeak,IS0_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_IS0_LIBRARY,total = len(FS_IS0_LIBRARY)):\n",
    "    IS0_pm.append(SPECTRUM['precursor_mz'])\n",
    "    IS0_npeak.append(SPECTRUM['n_peak'])\n",
    "    IS0_entropy.append(SPECTRUM['entropy'])\n",
    "IS0_DF = pd.DataFrame({\n",
    "    'entropy': IS0_entropy,\n",
    "    'PM': IS0_pm,\n",
    "    'NPEAK':IS0_npeak\n",
    "})\n",
    "\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4007cc-b3dd-4c46-8128-130fba90fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50000  # Randomly select one-tenth of the entire library\n",
    "i0_df = IS0_DF.sample(n=sample_size, random_state=42)\n",
    "width = 3.5\n",
    "height = width / 1.618\n",
    "plt.figure(figsize=(width*2 , height*2))\n",
    "kde = sns.kdeplot(\n",
    "    data=i0_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    cbar=True,\n",
    "    # cut=0,\n",
    "    color = '#1999B2'\n",
    ")\n",
    "\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/is0_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09220f-e173-4513-a749-06bac7247f46",
   "metadata": {},
   "source": [
    "## ISDB_e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94130247-a2d6-47e1-8868-51421d4974ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB_e1\n",
    "t = time.time()\n",
    "IS1_pm,IS1_npeak,IS1_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_IS1_LIBRARY,total = len(FS_IS1_LIBRARY)):\n",
    "    IS1_pm.append(SPECTRUM['precursor_mz'])\n",
    "    IS1_npeak.append(SPECTRUM['n_peak'])\n",
    "    IS1_entropy.append(SPECTRUM['entropy'])\n",
    "IS1_DF = pd.DataFrame({\n",
    "    'entropy': IS1_entropy,\n",
    "    'PM': IS1_pm,\n",
    "    'NPEAK':IS1_npeak\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7b6f8-219f-4adb-97b7-437f101ab04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50000  # Randomly select one-tenth of the entire library\n",
    "i1_df = IS1_DF.sample(n=sample_size)\n",
    "\n",
    "plt.figure(figsize=(width*2 , height*2))\n",
    "kde = sns.kdeplot(\n",
    "    data=i1_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    # cut=0,\n",
    "    cbar=True,\n",
    "    legend=False,\n",
    "    color = '#95BCE5'\n",
    ")\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/is1_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014763a-2b67-4c7a-b4fe-55cc05e089c5",
   "metadata": {},
   "source": [
    "## ISDB_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afa748-030f-4e7d-9715-72d86503fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISDB_e2\n",
    "t = time.time()\n",
    "IS2_pm,IS2_npeak,IS2_entropy = [],[],[]\n",
    "for SPECTRUM in tqdm(FS_IS2_LIBRARY,total = len(FS_IS2_LIBRARY)):\n",
    "    IS2_pm.append(SPECTRUM['precursor_mz'])\n",
    "    IS2_npeak.append(SPECTRUM['n_peak'])\n",
    "    IS2_entropy.append(SPECTRUM['entropy'])\n",
    "IS2_DF = pd.DataFrame({\n",
    "    'entropy': IS2_entropy,\n",
    "    'PM': IS2_pm,\n",
    "    'NPEAK':IS2_npeak\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea6970-c39e-4e0f-8014-db837e8bb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50000  # Randomly select one-tenth of the entire library\n",
    "i2_df = IS2_DF.sample(n=sample_size)\n",
    "\n",
    "plt.figure(figsize=(width*2 , height*2))\n",
    "kde = sns.kdeplot(\n",
    "    data=i2_df,\n",
    "    x='entropy',\n",
    "    y='PM',\n",
    "    fill=True,\n",
    "    common_grid=True,\n",
    "    common_norm=False,\n",
    "    bw_adjust=2,\n",
    "    # cut=0,\n",
    "    cbar=True,\n",
    "    legend=False,\n",
    "    color = '#F39DA0'\n",
    ")\n",
    "plt.ylim(0, 1500)\n",
    "plt.xlim(0, 6)\n",
    "plt.savefig(f'../msdb/data/pic/is2_distribution.png', dpi=300, bbox_inches= 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69e634-221c-4f4f-a958-b21cb405afe3",
   "metadata": {},
   "source": [
    "# R3Q14 Accuracy of ISDB\n",
    "##  Inner consistency of ISDB\n",
    "To answer Review3 comment 14\n",
    "### Pairwise Spectral similarity of ISDB_e0/e1/e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d7511-4d66-4eb9-a011-322da2e984ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pairwise similarity is calculated and saved using Scripts: \"../src/ICofIS.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2245d-13f7-47d4-8432-9aed4a1f9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id corresponds to Smile\n",
    "icis0 = functions_new.json_load('../msdb/data/ICofIS/is0_Id2Smile.json')\n",
    "icis1 = functions_new.json_load('../msdb/data/ICofIS/is1_Id2Smile.json')\n",
    "icis2 = functions_new.json_load('../msdb/data/ICofIS/is2_Id2Smile.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf96da5-9649-4674-b119-d8a895c75665",
   "metadata": {},
   "source": [
    "### Pairwise chemical similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aad24-c172-45ed-bbba-95922e2edea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The structural similarity can be calculated by \"../src/ICofIS_ChemSim.py\"  or the following code\n",
    "# Create fp database by FPsim2\n",
    "# Param: Index-to-SMILE, specific finger print type(Morgan_radius2_fpSize1024)\n",
    "# return: fp database file\n",
    "t = time.time() \n",
    "EL = 2 # 0, 1 Energy Lever\n",
    "ID2SMILE = functions_new.json_load(f'../msdb/data/ICofIS/is{EL}_Id2Smile.json')\n",
    "FPDB_FILE = f'../msdb/data/ICofIS/chem/is{EL}_fp_db.h5'\n",
    "OUTPUT_MATRIX = f'../msdb/data/ICofIS/chem/is{EL}_ICofIS.npy'\n",
    "\n",
    "IDX2SMILE = [[s['smile'],idx] for idx,s in enumerate(ID2SMILE)]\n",
    "\n",
    "if not os.path.exists(FPDB_FILE):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE, \n",
    "        filename=FPDB_FILE,\n",
    "        mol_format='smiles', # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')\n",
    "\n",
    "# Calculate structural similarity pair >= specific threshold (Dice_radius2_0.75)\n",
    "fpe = FPSim2Engine(FPDB_FILE)\n",
    "hit_dict = {}\n",
    "for idx,s in tqdm(enumerate(IDX2SMILE),total = len(IDX2SMILE)):\n",
    "    SMILE = s[0]\n",
    "    results = fpe.similarity(SMILE, threshold=0.75, metric='dice', n_workers=1)# [(LIBidx,similarity1),(),...]\n",
    "    fpidx_list = [x[0] for x in results]\n",
    "    fpsim_list = [x[1] for x in results]\n",
    "    if fpidx_list:\n",
    "        hit_dict[idx] = {'idx':fpidx_list,'sim_list':fpsim_list} # {LIBidx: {},{},..}\n",
    "\n",
    "# Save matrix\n",
    "ECHEM_MATRIX  = np.full((len(IDX2SMILE),len(IDX2SMILE)), 0.0, dtype=float) \n",
    "for key, value in hit_dict.items():\n",
    "    QueryIdx = key\n",
    "    MatchIdxs = value['idx']\n",
    "    MatchSim = value['sim_list']\n",
    "    for idx, MatchIdx in enumerate(MatchIdxs):\n",
    "        ECHEM_MATRIX[QueryIdx,MatchIdx] = MatchSim[idx]\n",
    "np.save(OUTPUT_MATRIX,ECHEM_MATRIX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48fa34-f272-47fb-a7a6-07d30d86554a",
   "metadata": {},
   "source": [
    "### Molecular networking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbf69c6-9bb0-435d-ab2b-232ced55d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering edges based on the spectral similarity matrix generated above to create MN using \"../src/ICofIS_networking.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d256b30-b923-4a2b-99aa-e4347fc6eec5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd517d1-dc08-46c4-b2c1-28ea70229d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the generated network using \"../src/ICofIS_evaluation.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eef124-e410-432c-961c-917d137c379b",
   "metadata": {},
   "source": [
    "### PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe8e98-de97-4e55-8e37-c3f33dd14e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp2arr(fp):\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f386d3-ba32-400a-8bfd-3586d74d0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sample represents the entire library\n",
    "# icis0, icis1, icis2 <dict> FS_IS0_LIBRARY\n",
    "class1=[]\n",
    "molecules=[]\n",
    "ecfp_1024=[]\n",
    "X = []\n",
    "CLASS1 = 'class1'\n",
    "CLASS2 = 'class2'\n",
    "for i in trange(len(icis0)):\n",
    "    try:\n",
    "        SMILE = icis0[i]['smile']\n",
    "        mol = Chem.MolFromSmiles(SMILE)\n",
    "        ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "        class1.append(CLASS1)\n",
    "        X.append(np.array(fp2arr(ecfp)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in trange(len(FS_IS0_LIBRARY)):\n",
    "    try:\n",
    "        SMILE = FS_IS0_LIBRARY[i]['smile']\n",
    "        mol = Chem.MolFromSmiles(SMILE)\n",
    "        ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "        class1.append(CLASS2)\n",
    "        X.append(np.array(fp2arr(ecfp)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "reduced_X = pca.transform(X)\n",
    "\n",
    "# Access the explained variance ratio of each principal component\n",
    "explained_var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio of each principal component\n",
    "pc1 = ''\n",
    "pc2 = ''\n",
    "pc3 = ''\n",
    "for i, var_ratio in enumerate(explained_var_ratio):\n",
    "    print(f'Principal Component {i + 1}: Explained Variance Ratio = {var_ratio:.4f}')\n",
    "    if i+1 == 1:\n",
    "        pc1 = f'{(var_ratio*100):.2f}%'\n",
    "    if i+1 == 2:\n",
    "        pc2 = f'{(var_ratio*100):.2f}%'\n",
    "    if i+1 == 3:\n",
    "        pc3 = f'{(var_ratio*100):.2f}%'\n",
    "    if i+1 > 2:break\n",
    "\n",
    "print(pc1,pc2,pc3)\n",
    "red_x, red_y, red_z= [], [], []\n",
    "blue_x, blue_y, blue_z = [], [], []\n",
    "green_x, green_y, green_z = [], [], []\n",
    "\n",
    "for i in trange(len(reduced_X)):\n",
    "    if class1[i] == CLASS1:\n",
    "        red_x.append(reduced_X[i][0])\n",
    "        red_y.append(reduced_X[i][1])\n",
    "\n",
    "    elif class1[i] == CLASS2:\n",
    "        blue_x.append(reduced_X[i][0])\n",
    "        blue_y.append(reduced_X[i][1])\n",
    "  \n",
    "\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(red_x, red_y, c='#1A51AD', marker='o', label='selected',alpha=0.5)\n",
    "ax.scatter(blue_x, blue_y, c='gray', marker='o', label='ISDB',alpha=0.015)\n",
    "ax.legend()\n",
    "ax.set_xlabel(f'PC1 ({pc1})')\n",
    "ax.set_ylabel(f'PC2 ({pc2})')\n",
    "ax.set_title('2D PCA')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61830f-f67e-4d0d-8172-52362c92b131",
   "metadata": {},
   "source": [
    "## Similarity between in-silico and experimental spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e69162-622d-459b-aaa8-a9c8b63112ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate\n",
    "temp = functions_new.json_load('../msdb/FS_edb_smi.json')\n",
    "e_search = FlashEntropySearch()\n",
    "FS_E_LIBRARY = e_search.build_index(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b07a163c-4952-458f-b257-5f8e0d22b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain spectra with non-redunant similes in experimental library\n",
    "dup_E_LIBRARY = list({s['smile']: s for s in FS_E_LIBRARY}.values()) \n",
    "ISDB_list = list(ISDB_INFO) # Keys of ISDB_INFO <list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dd9af-c239-4a05-b612-e994337921f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnps_is:h qtof (47192, 467124)\n",
    "# Create fp databased by FPsim2\n",
    "# Param: Index-to-SMILE, specific finger print type(Morgan_radius2_fpSize1024)\n",
    "# return: fp database file\n",
    "t = time.time() \n",
    "DIR = f'../msdb/data/ICofIS/'\n",
    "FPDB_FILE = os.path.join(DIR,f'chem/fp_db_gnps_is.h5')\n",
    "OUTPUT_MATRIX = os.path.join(DIR,f'chem/gnps_is.npy')\n",
    "\n",
    "IDX2SMILE = []\n",
    "for idx, (key, values) in enumerate(ISDB_INFO.items()):\n",
    "    IDX2SMILE.append([values['smiles'],idx])\n",
    "\n",
    "if not os.path.exists(FPDB_FILE):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE, \n",
    "        filename=FPDB_FILE,\n",
    "        mol_format='smiles', # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )\n",
    "print(f'Finished in {(time.time() - t) / 60:.2f} min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b5a6c37-a384-47c7-83b6-f5f84d68421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find identical GNPS-smile in isdb\n",
    "# Calculate structural similarity pair >= specific threshold (Dice_radius2_1)\n",
    "# FS_SPECTRA: hqtof\n",
    "fpe = FPSim2Engine(FPDB_FILE)\n",
    "hit_dict = {}\n",
    "for idx,s in enumerate(dup_E_LIBRARY):\n",
    "    SMILE = s['smile']\n",
    "    results = fpe.similarity(SMILE, threshold=1, metric='dice', n_workers=1)# [(LIBidx,similarity1),(),...]\n",
    "    fpidx_list = [x[0] for x in results]\n",
    "    fpsim_list = [x[1] for x in results]\n",
    "    if fpidx_list:\n",
    "        hit_dict[idx] = {'idx':fpidx_list,'sim_list':fpsim_list} # {LIBidx: {},{},..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "29148faf-5193-4c20-86d5-b0e8c5f38836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18983 gnps-smiles found identical match in isdb\n",
    "ALGO = 'entropy'\n",
    "for key, values in hit_dict.items():\n",
    "    dup_E_SPECTRUM = dup_E_LIBRARY[key]\n",
    "    PM = dup_E_SPECTRUM['precursor_mz']\n",
    "    SPEC = dup_E_SPECTRUM['peaks']\n",
    "    SPEC = spectral_entropy.clean_spectrum(SPEC, max_mz=PM+0.01) # MS2 spectrum clean by normalizing and removing signals with intensity less than 1% of the base peak\n",
    "    SPECTRUM = Spectrum(mz=np.array(SPEC[:, 0],dtype = float),\n",
    "                  intensities=np.array(SPEC[:, 1],dtype = float),\n",
    "                  metadata={\"precursor_mz\": PM})\n",
    "    \n",
    "    \n",
    "    ISDB_idx = values['idx'][0]\n",
    "    ISDB_ID = ISDB_list[ISDB_idx]\n",
    "    e0_ms2,e0_spectrum,e1_ms2,e1_spectrum,e2_ms2,e2_spectrum = functions_new.get_spectra_from_isinfo(ISDB_INFO,ISDB_ID)\n",
    "\n",
    "    SIM0, MP0 = functions_new.clac_spec_sim(SPEC,SPECTRUM,e0_ms2,e0_spectrum,ALGO)\n",
    "    SIM1, MP1 = functions_new.clac_spec_sim(SPEC,SPECTRUM,e1_ms2,e1_spectrum,ALGO)\n",
    "    SIM2, MP2 = functions_new.clac_spec_sim(SPEC,SPECTRUM,e2_ms2,e2_spectrum,ALGO)\n",
    "\n",
    "    dup_E_SPECTRUM[f'{ALGO}_sim0'] = round(SIM0,2)\n",
    "    dup_E_SPECTRUM[f'{ALGO}_mp0'] = MP0\n",
    "    dup_E_SPECTRUM[f'{ALGO}_sim1'] = round(SIM1,2)\n",
    "    dup_E_SPECTRUM[f'{ALGO}_mp1'] = MP1\n",
    "    dup_E_SPECTRUM[f'{ALGO}_sim2'] = round(SIM2,2)\n",
    "    dup_E_SPECTRUM[f'{ALGO}_mp2'] = MP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31e2586f-69e5-4888-bd2b-b5473b9418d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'CCMSLIB00000427077', 'precursor_mz': 32.05, 'peaks': array([[30.,  1.]], dtype=float32), 'smile': 'CN', 'charge': 1, 'ion_mode': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "dup_E_LIBRARY[19]\n",
    "for r in dup_E_LIBRARY:\n",
    "    print(r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "55e2ca8d-bdb3-423e-8a61-cf95399b5064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09993151767370806% pairs higher than 0.6\n",
      "0.276563240794395% pairs higher than 0.35 and lower than 0.6\n",
      "0.6691250065848391% pairs lower than 0.35\n"
     ]
    }
   ],
   "source": [
    "ALGO = 'peak_percentage'\n",
    "keys = [f'{ALGO}_sim0',f'{ALGO}_mp0',\n",
    "        f'{ALGO}_sim1',f'{ALGO}_mp1',\n",
    "        f'{ALGO}_sim2',f'{ALGO}_mp2']\n",
    "stats = {keys[0]:[],keys[1]:[],keys[2]:[],keys[3]:[],keys[4]:[],keys[5]:[]}\n",
    "for SPECTRUM in dup_E_LIBRARY:\n",
    "    for key in keys:\n",
    "        try:\n",
    "            stats[key].append(SPECTRUM[key])\n",
    "        except:\n",
    "            pass\n",
    "idx1,idx3,idx5 = 0,2,4\n",
    "total = len(stats[keys[idx1]])\n",
    "print(f'{len([x for x in stats[keys[idx5]] if x >= 0.6])/total}% pairs higher than 0.6')\n",
    "print(f'{len([x for x in stats[keys[idx1]] if 0.7 > x >= 0.35])/total}% pairs higher than 0.35 and lower than 0.6')\n",
    "print(f'{len([x for x in stats[keys[idx1]] if 0.35 > x])/total}% pairs lower than 0.35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "75cbe14a-eba7-4e6b-b351-5c4d128cdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.rcParams['font.sans-serif'] = ['Arial'] \n",
    "fig, ax1 = plt.subplots(figsize=(3, 6))\n",
    "idx1,idx2 = 4,5\n",
    "x_ls = np.zeros(len(stats[keys[idx1]]))     \n",
    "x_hs = np.ones(len(stats[keys[idx2]]))      \n",
    "\n",
    "# Violin plot of low similarity pairs\n",
    "# sns.violinplot(y=stats[keys[0]], color='blue', inner=None, ax=ax1, width=0.5)\n",
    "sns.violinplot(x=x_ls, y=stats[keys[idx1]],\n",
    "               color='#F5A889', inner=None, width=0.4, ax=ax1)\n",
    "ax1.set_title(f\"{keys[idx1]}\")\n",
    "ax1.set_ylabel(\"Spectral similarity\", color='black')\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "ax1.xaxis.set_ticks_position('none') \n",
    "ax1.yaxis.set_ticks_position('none')  \n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "ax2.spines['right'].set_position(('outward', -3)) \n",
    "\n",
    "# Violin plot of high similarity pairs\n",
    "sns.violinplot(x=x_hs, y=stats[keys[idx2]],\n",
    "               color='#ACD6EC', inner=None, width=0.4, ax=ax2)\n",
    "ax2.set_ylabel(\"Shared peaks\", color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(DIR,f'pic/violion_{keys[idx1]}.png'), dpi=500, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ea8a0-535f-4d38-907c-9c34a05e491a",
   "metadata": {},
   "source": [
    "# Figure 2G-I Comparative analysis\n",
    "Calculating pairwise spectral and structural similarity based on the curated hqtof dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d66495-490a-436c-895f-cee6eed97aff",
   "metadata": {},
   "source": [
    "## Pairwise spectral similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37d016-3719-4f89-aba9-07f0fe5eed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is performed by \"../src/hqtof_pair.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dda317-a3ee-4a0c-bff4-acb8db33c689",
   "metadata": {},
   "source": [
    "## Pairwise chemical similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9275f6f-d8f7-4e19-9fdb-9fefbec16a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FP database\n",
    "IDX2SMILE = []\n",
    "for idx, SPEC in tqdm(enumerate(Hqtof_CCMSIDs), total=len(Hqtof_CCMSIDs)):\n",
    "    CCMSID = Hqtof_CCMSIDs[idx]\n",
    "    SMILE = GNPS_INFO[CCMSID]['SMILE']\n",
    "    IDX2SMILE.append([SMILE, idx])\n",
    "\n",
    "FPDB = f'../msdb/data/hqtof/chem/hqtof_fp_db.h5'\n",
    "if not os.path.exists(FPDB):\n",
    "    create_db_file(\n",
    "        mols_source=IDX2SMILE,\n",
    "        filename=FPDB,\n",
    "        mol_format='smiles',  # required\n",
    "        fp_type='Morgan',\n",
    "        fp_params={'radius': 2, 'fpSize': 1024}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843dad67-c2da-4a15-9ded-abef2fd7096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_SPECTRA search against FS_E_LIB\n",
    "fpe = FPSim2Engine(fp_filename=FPDB)\n",
    "hit_dict = {}\n",
    "for idx in trange(len(Hqtof_CCMSIDs)):\n",
    "    try:\n",
    "        CCMSID = Hqtof_CCMSIDs[idx]\n",
    "        SMILE = GNPS_INFO[CCMSID]['SMILE']\n",
    "        results = fpe.similarity(SMILE, threshold=0, metric='dice', n_workers=1)  # [(LIBidx,similarity1),(),...]\n",
    "        results = [x for x in results if x[0] != idx] # Remove self comparison\n",
    "        fpidx_list = [x[0] for x in results]\n",
    "        fpsim_list = [x[1] for x in results]\n",
    "\n",
    "        if fpidx_list:\n",
    "            hit_dict[idx] = {'idx': fpidx_list, 'sim_list': fpsim_list}  # {LIBidx: {},{},..}\n",
    "    except:print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4494a-60c2-4a8b-9ea8-fab924628964",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECHEM_MATRIX  = np.full((len(Hqtof_CCMSIDs),len(Hqtof_CCMSIDs)), 0.0, dtype=float) \n",
    "for key, value in hit_dict.items():\n",
    "    QueryIdx = key\n",
    "    MatchIdxs = value['idx']\n",
    "    MatchSim = value['sim_list']\n",
    "    for idx, MatchIdx in enumerate(MatchIdxs):\n",
    "        ECHEM_MATRIX[QueryIdx,MatchIdx] = MatchSim[idx]\n",
    "\n",
    "# Save results\n",
    "DIR = '../msdb/data/hqtof/chem/'\n",
    "np.save(os.path.join(DIR,f'hqtof_dice.npy'),ECHEM_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cae0a-a557-4c0a-b502-549be6755e33",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "TP, FP, TN, FN, ROC, FDR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fc52a-769f-43b8-bf79-022b71f5898f",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "Add class distribution\n",
    "In sklearn.metrices: TN:`C_{0,0}`, FN:`C_{1,0}`, TP: `C_{1,1}` and FP: `C_{0,1}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018b9e3-3963-46b2-ae47-597d384a1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and parameters\n",
    "# Parameters \n",
    "CHEM_THRESHOLD = 0.7\n",
    "SPEC_THRESHOLD = 0.7 # Thresholds\n",
    "PEAK_THRESHOLD = 6\n",
    "\n",
    "ALGORITHMs = G1 + G2 + G3\n",
    "# ALGORITHMs = ['peak_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880eb2c-68dd-447f-bf22-33fac8fb5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc51eb-5ce0-4a7d-94ab-1d07b08a7b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROC curve without shared peak matrix\n",
    "# Save roc_auc curve \n",
    "plt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "AUC_DICT = {}\n",
    "for ALGORITHM in tqdm(ALGORITHMs):\n",
    "    # try:\n",
    "        SPEC_SIM_MATRIX = np.load(f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy')\n",
    "        LABELs,SPEC_SIMILARITYs = [],[]\n",
    "        TEMP_INFO = {}\n",
    "        for idx1 in range(len(IDXtoCCMSID)):    \n",
    "            for idx2 in range(idx1):\n",
    "                CHEM_SIM = TANIMOTO_MATRIX[idx1,idx2]\n",
    "                SPEC_SIM = SPEC_SIM_MATRIX[idx1,idx2]\n",
    "                SPEC_SIMILARITYs.append(SPEC_SIM)\n",
    "                \n",
    "                if CHEM_SIM >= CHEM_THRESHOLD:\n",
    "                    LABELs.append(1)\n",
    "                else:\n",
    "                    LABELs.append(-1)\n",
    "                    \n",
    "        FPRs,TPRs, THRESHOLDs = roc_curve(LABELs, SPEC_SIMILARITYs)\n",
    "        AUC = auc(FPRs,TPRs)\n",
    "        YOUDEN = [TPRs[i] - FPRs[i] for i in range(len(THRESHOLDs))]\n",
    "        OPTIMAL_THRESHOLD = THRESHOLDs[YOUDEN.index(max(YOUDEN))] # Optimal threshold\n",
    "        AUC_DICT[f'{ALGORITHM}'] = {'AUC':AUC,'OT':OPTIMAL_THRESHOLD}\n",
    "        if ALGORITHM == 'modifeid_cosine':\n",
    "            plt.plot(FPRs, TPRs, color=\"red\",alpha = 0.7, lw= 1.5, label=f\"ROC curve (area = {AUC:.3f})\")\n",
    "        if ALGORITHM == 'entropy':\n",
    "            plt.plot(FPRs, TPRs, color=\"blue\",alpha = 0.7, lw = 1.5, label=f\"ROC curve (area = {AUC:.3f})\")            \n",
    "        else:\n",
    "            plt.plot(FPRs, TPRs, color=\"grey\",alpha = 0.7, lw = 0.8, label=f\"ROC curve (area = {AUC:.3f})\")\n",
    "    # except:print(ALGORITHM)\n",
    "        \n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\", fontname='Arial', fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontname='Arial', fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12,\n",
    "                labelfontfamily ='Arial', labelcolor='black', width=1, length=2)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.title(\"Receiver Operating Characteristic\")\n",
    "# plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "# plt.savefig(\"../msdb/data/pic/ROC_AUC.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.savefig(\"../msdb/data/pic/ROC_AUC.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "with open(\"../msdb/data/pic/ROC_AUC.json\",'w') as f: # Save ROC_AUC json\n",
    "    json.dump(AUC_DICT,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba1dd7-e491-4de9-b097-b6fe06b8dec8",
   "metadata": {},
   "source": [
    "### FDR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c14cc-5cb2-400b-b866-305dd505d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MS1MATCH = 0\n",
    "for idx1 in trange(len(IDXtoCCMSID)):    \n",
    "    for idx2 in range(idx1):\n",
    "        if MS1_MATCH_MATRIX[idx1,idx2] == 1:\n",
    "            N_MS1MATCH += 1 \n",
    "print(N_MS1MATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207fa85d-3cb8-4e81-b7b7-f2878c9f6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR v.s. similarity plotting\n",
    "FDR_DICT = {}\n",
    "for ALGORITHM in tqdm(['modified_cosine']):#tqdm(ALGORITHMs[:1]):\n",
    "    try:\n",
    "        SPEC_SIM_MATRIX = np.load(f'../msdb/data/matrix/{ALGORITHM}_similarity_matrix.npy')\n",
    "        LABELs,SPEC_SIMILARITYs = [],[]\n",
    "        TEMP_INFO = {}\n",
    "        for idx1 in range(len(IDXtoCCMSID)):    \n",
    "            for idx2 in range(idx1):\n",
    "                CHEM_SIM = TANIMOTO_MATRIX[idx1,idx2]\n",
    "                SPEC_SIM = SPEC_SIM_MATRIX[idx1,idx2]          \n",
    "                \n",
    "                SPEC_SIMILARITYs.append(SPEC_SIM)\n",
    "                if CHEM_SIM >= CHEM_THRESHOLD:\n",
    "                    LABELs.append(1)\n",
    "                else:\n",
    "                    LABELs.append(-1)\n",
    "                    \n",
    "        FPRs,TPRs, THRESHOLDs = roc_curve(LABELs, SPEC_SIMILARITYs)\n",
    "        FDRs = [] # Calculate FDR\n",
    "        for THRESHOLD in tqdm(THRESHOLDs,total=len(THRESHOLDs)):\n",
    "            Y_PREDCTIONs = []\n",
    "            for idx1 in range(len(IDXtoCCMSID)):\n",
    "                for idx2 in range(idx1):\n",
    "                    SPEC_SIM = SPEC_SIM_MATRIX[idx1,idx2]\n",
    "                    MS1_MATCH = MS1_MATCH_MATRIX[idx1,idx2]\n",
    "                    if SPEC_SIM >= THRESHOLD and MS1_MATCH == 1:\n",
    "                        Y_PREDCTIONs.append(1)\n",
    "                    else: \n",
    "                        Y_PREDCTIONs.append(-1)\n",
    "            CONFUSION_METRIX = confusion_matrix(LABELs, Y_PREDCTIONs)  \n",
    "            \n",
    "            TP,FP = CONFUSION_METRIX[1,1],CONFUSION_METRIX[0,1]\n",
    "            if (TP + FP) == 0:\n",
    "                FDRs.append(0) \n",
    "            else:\n",
    "                FDRs.append(FP/(TP+FP))\n",
    "\n",
    "        plt.plot(THRESHOLDs,FDRs,'b*-',label = f'ROC curve of {ALGORITHM}')\n",
    "    except:print(ALGORITHM)\n",
    "        \n",
    "# plt.plot([0,1],[0,1],'r--',label = '45° reference')\n",
    "plt.legend()\n",
    "plt.xlabel('Spectral similarity score')\n",
    "plt.ylabel('False-discovery rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fc531-bb50-4bb3-9a24-5deb3bf84438",
   "metadata": {},
   "source": [
    "### Spectral similariry distribution compared to modified cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760f88b-dbd0-446b-a685-b3a53f6b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectral similarity matrices\n",
    "G1,G2,G3 = evaluation.get_groups()\n",
    "TALGOs = G1 + G2\n",
    "TALGOs.remove('modified_cosine')\n",
    "\n",
    "# ALGORITHMs.insert(0, 'cosine')\n",
    "# ALGORITHMs.insert(0, 'modified_cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d15fb-9541-462b-9fa2-69a00bdd459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D hist\n",
    "DIR = f'../msdb/data/hqtof/SpecSimMatrix/'\n",
    "ALGORITHMs = ['cosine']\n",
    "for ALGO in ALGORITHMs:\n",
    "    plt.figure(figsize=(6, 1.2), constrained_layout=True)\n",
    "    \n",
    "    SIMILARITY = [] # Hist data    \n",
    "    SPEC_SIM_MATRIX = np.load(os.path.join(DIR,f'{ALGO}.npy'))\n",
    "    for idx1 in range(len(SPEC_SIM_MATRIX)):\n",
    "        for idx2 in range(idx1):\n",
    "            SIMILARITY.append(SPEC_SIM_MATRIX[idx1,idx2])\n",
    "    sns.kdeplot(\n",
    "        data=SIMILARITY,\n",
    "        # x=xlabel,\n",
    "        lw =0.5,\n",
    "        clip=(0, 1),\n",
    "        legend=True,\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        bw_method= 0.2,\n",
    "        warn_singular=False\n",
    "        )\n",
    "    plt.axis('off')\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "    plt.savefig(f'../msdb/data/pic/hist/{ALGO}_hist.png', dpi=300, bbox_inches= 'tight',pad_inches=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1323dcd-7241-4f8d-9a48-80c9c362f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectral similarity matrices\n",
    "# Param\n",
    "\n",
    "DIR = f'../msdb/data/hqtof/' # former: f'../msdb/data/hqtof/matrix/'\n",
    "ALGORITHMs = ['modified_cosine']\n",
    "OTHERs = [a for a in TALGOs if a not in ALGORITHMs]\n",
    "OTHERs = ['cosine']\n",
    "BINs = 75\n",
    "\n",
    "for idx1 in range(len(OTHERs)):\n",
    "    ALGORITHM1 = OTHERs[idx1]\n",
    "    SPEC_SIM_MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM1}.npy'))\n",
    "    SIMILARITY1 = []\n",
    "    for i in range(len(SPEC_SIM_MATRIX1)):\n",
    "        for j in range(i):\n",
    "            SIMILARITY1.append(SPEC_SIM_MATRIX1[i,j])\n",
    "    \n",
    "    for idx2 in range(len(ALGORITHMs)):\n",
    "        ALGORITHM2 = ALGORITHMs[idx2]\n",
    "        SPEC_SIM_MATRIX2 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM2}.npy'))\n",
    "        SIMILARITY2 = []\n",
    "        for i in range(len(SPEC_SIM_MATRIX2)):\n",
    "            for j in range(i):\n",
    "                SIMILARITY2.append(SPEC_SIM_MATRIX2[i,j])\n",
    "                \n",
    "        \n",
    "        tick_locators = mticker.FixedLocator(np.arange(0, BINs + 1, BINs / 4))\n",
    "        tick_labels = np.asarray([f\"{a:.2f}\" for a in np.arange(0, 1.01, 0.25)])\n",
    "        \n",
    "        fig, axe = plt.subplots(constrained_layout=True,figsize=(6, 6))\n",
    "        \n",
    "        hist, _, _ = np.histogram2d(\n",
    "            SIMILARITY1, # X label\n",
    "            SIMILARITY2, # Y label\n",
    "            bins = BINs,\n",
    "            range=[[0, 1], [0, 1]],\n",
    "        )\n",
    "        hist /= len(SIMILARITY1)\n",
    "        heatmap = sns.heatmap(\n",
    "            np.rot90(hist),\n",
    "            vmin=0.0,\n",
    "            vmax=0.001,\n",
    "            cmap=\"viridis\",\n",
    "            cbar = i == 2,\n",
    "            cbar_ax = cbar_ax if i == 2 else None,\n",
    "            # cbar=True, # Legend \n",
    "            cbar_kws={\"format\": mticker.StrMethodFormatter(\"{x:.3%}\")},\n",
    "            square=True,\n",
    "            xticklabels=False,\n",
    "            yticklabels=False,\n",
    "            norm=LogNorm(vmax=0.001),\n",
    "            ax = axe\n",
    "        )\n",
    "        \n",
    "        # # axe.plot([0, hist.shape[0]], [hist.shape[0] , 0], color='red', linewidth=1,linestyle=\"--\")\n",
    "        axe.yaxis.set_major_locator(tick_locators)\n",
    "        axe.xaxis.set_major_locator(tick_locators)\n",
    "        axe.set_yticklabels(tick_labels[::-1]) # Reverse\n",
    "        axe.set_xticklabels(tick_labels)\n",
    "        axe.set_xlabel(ALGORITHM1, fontname='Arial', fontsize=12)\n",
    "        axe.set_ylabel(ALGORITHM2, fontname='Arial', fontsize=12)\n",
    "        \n",
    "        axe.tick_params(axis='both', which='major', labelsize=12, labelfontfamily ='Arial', width=1, length=5) # Font settings\n",
    "        # axe.xaxis.set_major_formatter(mticker.PercentFormatter())\n",
    "        for _, spine in heatmap.spines.items():\n",
    "            spine.set_visible(True)\n",
    "\n",
    "        \n",
    "        axe.plot(\n",
    "            [0, BINs], [BINs, 0], color=\"red\", linestyle=\"dashed\"\n",
    "        )\n",
    "        \n",
    "        sns.despine(ax=axe) # Remove top and right border\n",
    "        \n",
    "    \n",
    "        # plt.show()\n",
    "        plt.savefig(os.path.join(DIR,f'2Dhist/{ALGORITHM2}Y_{ALGORITHM1}X_2Dhist.png'), dpi=500, bbox_inches= 'tight',pad_inches=0.5)\n",
    "        # plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea0a82-1f68-40b8-8432-b9f547739ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate specific \n",
    "DIR = '../msdb/data/hqtof/'\n",
    "ALGORITHM1 = 'modified_cosine'\n",
    "MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM1}.npy'))\n",
    "\n",
    "G1,G2,G3 = evaluation.get_groups()\n",
    "TAs = G1+G2+G3\n",
    "TAs = ['dot_product_reverse']\n",
    "for ALGORITHM2 in TAs:\n",
    "    # ALGORITHM2 = 'entropy' #ALGORITHMs[0]\n",
    "    MATRIX2 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM2}.npy'))\n",
    "    \n",
    "    mask = np.triu_indices_from(MATRIX1, k=0) # The upper triangle without diagonal\n",
    "    count = np.sum(MATRIX2[mask] > MATRIX1[mask]) # 比较 MATRIX2 > MATRIX1 的位置\n",
    "    \n",
    "    n = MATRIX1.shape[0]\n",
    "    upper_indices = np.triu_indices(n, k=0) # The upper triangle without diagonal\n",
    "    total_count = len(upper_indices[0])\n",
    "    \n",
    "    pp = round(count/total_count,2)*100\n",
    "    \n",
    "    print(f'{ALGORITHM2} socore higher than {ALGORITHM1} in {pp}% spectral pairs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8994e-d2fe-4aa8-8d08-acd3d7479b32",
   "metadata": {},
   "source": [
    "### Spectral and chemical similarity correlation\n",
    "Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669a70f-5c6c-4761-9bb4-f0e5dd78a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1,G2,G3 = evaluation.get_groups()\n",
    "ALGOs = G1+G2+G3\n",
    "# ALGORITHM = [a for a in ALGORITHMs if 'modified_cosine' in a][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93038897-a394-4529-b950-0c5cf6d67d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load spec matrix\n",
    "DIR = '../msdb/data/hqtof/matrix/'\n",
    "ALGO = 'dice'\n",
    "for ALGO in tqdm(ALGOs,total=len(ALGOs)):\n",
    "    try:\n",
    "        ChemSimMat = np.load('../msdb/data/hqtof/chem/ChemSim.npy')\n",
    "        SpecSimMat = np.load(os.path.join(DIR,f'{ALGO}_similarity_matrix.npy'))\n",
    "        \n",
    "        # High sim pairs\n",
    "        HSIdx = [np.where(arr >=0.7) for arr in ChemSimMat] # [(),(),...] list containing tuples\n",
    "        HSSpecSim = [SpecSimMat[idx][HSIdx[idx]] for idx in range(len(HSIdx)) if HSIdx[idx][0].any()]\n",
    "        # HSChemSim = [ChemSimMat[idx][HSIdx[idx]] for idx in range(len(HSIdx)) if HSIdx[idx][0].any()] \n",
    "        \n",
    "        HS_values = np.concatenate(HSSpecSim)\n",
    "        \n",
    "        # Low sim pairs\n",
    "        LSIdx = [np.where((arr >= 0.1) & (arr < 0.35)) for arr in ECHEM_MATRIX] \n",
    "        LSSpecSim = [SpecSimMat[idx][LSIdx[idx]] for idx in range(len(LSIdx)) if LSIdx[idx][0].any()]\n",
    "        LSChemSim = [ChemSimMat[idx][LSIdx[idx]] for idx in range(len(LSIdx)) if LSIdx[idx][0].any()] \n",
    "        \n",
    "        LS_values = np.concatenate(LSSpecSim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        data_ls = pd.DataFrame({'Values': LS_values, 'Type': 'LS'})\n",
    "        data_hs = pd.DataFrame({'Values': HS_values, 'Type': 'HS'})\n",
    "        \n",
    "        # 创建一个共享 x 轴的双 y 轴图\n",
    "        fig, ax1 = plt.subplots(figsize=(3, 6))\n",
    "        \n",
    "        # 绘制 LS_values 的小提琴图\n",
    "        sns.violinplot(x='Type', y='Values', data=data_ls, ax=ax1, color='blue', width=0.5,inner=None)\n",
    "        ax1.set_title(f\"{ALGO}\")\n",
    "        ax1.set_ylabel(\"LS Values\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        # 隐藏 ax1 的边框\n",
    "        for spine in ax1.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        ax1.xaxis.set_ticks_position('none')  # 隐藏 x 轴刻度\n",
    "        ax1.yaxis.set_ticks_position('none')  # 隐藏 y 轴刻度\n",
    "        \n",
    "        ax2 = ax1.twinx() # 创建第二个 y 轴\n",
    "        \n",
    "        ax2.spines['right'].set_position(('outward', -3)) # 调整 ax2 的位置，使其更靠近 ax1\n",
    "        \n",
    "        # 绘制 HS_values 的小提琴图\n",
    "        sns.violinplot(x='Type', y='Values', data=data_hs, ax=ax2, color='red', width=0.5,inner=None)\n",
    "        ax2.set_ylabel(\"HS Values\", color='red')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        \n",
    "        # 隐藏 ax2 的边框\n",
    "        for spine in ax2.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        \n",
    "        # 调整布局\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../msdb/data/hqtof/pic_violin/{ALGO}.png', dpi=500, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    except:print(ALGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f897d07-2d84-4ef8-a985-cf185056efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "print(FS_SPECTRA[1]['smile'])\n",
    "print(FS_SPECTRA[113]['smile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edd9fa-c07b-4fd3-928a-4afe8a3b8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_SPECTRA[113]['peaks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a80ba1-1e4e-4b22-8c93-f4391398fc3c",
   "metadata": {},
   "source": [
    "## Detailed inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2231ef-a045-401e-b0f5-db2aa604b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hqtof_CCMSIDs = list(np.load('../msdb/data/hqtof/idlist/H_qtof_non-redundant_CCMSIDs.npy'))\n",
    "# Load processed json file\n",
    "GNPS_INFO = functions_new.json_load('../msdb/GNPSLIBRARY/GNPS-LIBRARY-INFO.json')\n",
    "\n",
    "modified_cosine = ModifiedCosine(tolerance = 0.05)\n",
    "neutral_loss = NeutralLossesCosine(tolerance = 0.05)\n",
    "cosine = CosineGreedy(tolerance=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546deb8d-eb91-4ae9-9323-ace4f532eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimial threholds\n",
    "optimal_threshold = {'modified_cosine': 0.72, 'weighted_dot_product': 0.89, 'hellinger': 0.18, 'ms_for_id': 0.205, 'manhattan': 0.535,\n",
    "            'absolute_value': 0.535, 'intersection': 0.535, 'lorentzian': 0.52, 'ruzicka': 0.365, 'motyka': 0.535, 'fidelity': 0.72,\n",
    "            'bhattacharya_2': 0.755, 'matusita': 0.475, 'bhattacharya_1': 0.765, 'squared_chord': 0.72, 'vicis_symmetric_chi_squared_3': 0.625,\n",
    "            'probabilistic_symmetric_chi_squared': 0.67, 'harmonic_mean': 0.67, 'unweighted_entropy': 0.700, 'improved_similarity': 0.515,\n",
    "            'clark': 0.515, 'spectral_contrast_angle': 0.72, 'pearson_correlation': 0.845, 'dot_product': 0.72, 'inner_product': 0.1,\n",
    "            'whittaker_index_of_association': 0.11, 'dot_product_reverse': 0.99, 'avg_l': 0.175, 'entropy': 0.535, 'roberts': 0.285,\n",
    "            'baroni_urbani_buser': 0.735, 'neutral_loss': 0.72, 'jaccard': 0.54, 'dice': 0.52, 'peak_percentage': 0.71, 'squared_euclidean': 0.975,\n",
    "            'euclidean': 0.84, 'penrose_shape': 0.84, 'chebyshev': 0.885, 'ms_for_id_v1': 0.98, 'canberra': 0.055, 'divergence': 0.03, 'wave_hedges': 0.055,\n",
    "            'penrose_size': 0.23, 'mean_character': 0.985, 'symmetric_chi_squared': 0.950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9318b33-53aa-4c8d-82e9-fd98fcdf06c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2571, 2571)\n"
     ]
    }
   ],
   "source": [
    "DIR = '../msdb/data/hqtof'\n",
    "ALGORITHM1 = 'modified_cosine'\n",
    "MATRIX1 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM1}.npy'))\n",
    "\n",
    "ALGORITHM2 = 'peak_percentage'\n",
    "MATRIX2 = np.load(os.path.join(DIR,f'SpecSimMatrix/{ALGORITHM2}.npy'))\n",
    "\n",
    "ChemSimMat = np.load(os.path.join(DIR,f'chem/hqtof_dice.npy'))\n",
    "\n",
    "# Get part of score higher\n",
    "i, j = np.triu_indices_from(MATRIX1, k=1)  # The upper triangle without diagonal\n",
    "mask_condition = MATRIX2[i, j] > MATRIX1[i, j]\n",
    "indices = (i[mask_condition], j[mask_condition])\n",
    "pair_indices = list(zip(indices[0],indices[1]))\n",
    "\n",
    "\n",
    "mask_condition1 = MATRIX2[i, j] < MATRIX1[i, j] # Mask where MATRIX2 is less than MATRIX1\n",
    "less_than_indices = (i[mask_condition1], j[mask_condition1]) # Use the mask to get the relevant indices\n",
    "less_than_pair_indices = list(zip(less_than_indices[0], less_than_indices[1])) # Create a list of paired indices\n",
    "\n",
    "\n",
    "TPs, FPs, TNs, FNs = [],[],[],[]\n",
    "for i in tqdm(less_than_pair_indices,total = len(less_than_pair_indices)):\n",
    "    idx1,idx2 = i\n",
    "    SIM1 = MATRIX1[idx1,idx2]\n",
    "    SIM2 = MATRIX2[idx1,idx2]\n",
    "    diff = abs(SIM1-SIM2)\n",
    "    ChemSim = ChemSimMat[idx1,idx2]\n",
    "    OT = optimal_threshold[ALGORITHM1]\n",
    "    # if diff >= 0: # Filter by similarity difference\n",
    "    \n",
    "    if SIM1 > 0 and SIM2 >= OT and ChemSim >= 0.75:\n",
    "        TPs.append(i)\n",
    "    elif SIM1 > 0 and SIM2 >= OT and ChemSim < 0.75:\n",
    "        FPs.append(i)\n",
    "    elif SIM1 > 0 and SIM2 < OT and ChemSim >= 0.75:\n",
    "        FNs.append(i)\n",
    "    elif SIM1 > 0 and SIM2 < OT and ChemSim < 0.75:\n",
    "        TNs.append(i)\n",
    "len(TPs),len(FPs),len(TNs),len(FNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d156e7-890d-4cca-889a-c7cfbbf30a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIR = TPs[0]\n",
    "idx1, idx2 = PAIR[0],PAIR[1]\n",
    "CCMSID1,CCMSID2 = Hqtof_CCMSIDs[idx1], Hqtof_CCMSIDs[idx2]\n",
    "SPEC1, SPECTRUM1 = functions_new.gnps_info_format(GNPS_INFO,CCMSID1)\n",
    "SPEC2, SPECTRUM2 = functions_new.gnps_info_format(GNPS_INFO,CCMSID2)\n",
    "SIM1,MP1 = functions_new.clac_spec_sim(SPEC1, SPECTRUM1,SPEC2, SPECTRUM2,ALGORITHM1)\n",
    "SIM2,MP2 = functions_new.clac_spec_sim(SPEC1, SPECTRUM1,SPEC2, SPECTRUM2, ALGORITHM2)\n",
    "PM1, PM2 = float(GNPS_INFO[CCMSID1][\"PEPMASS\"]),float(GNPS_INFO[CCMSID2][\"PEPMASS\"])\n",
    "print(f'Top {CCMSID1}, precursor {PM1}')\n",
    "print(f'Bottom {CCMSID2}, precursor {PM2}')\n",
    "print(f\"Re-calced {ALGORITHM1}:{round(SIM1,2)}\",f\"{ALGORITHM2}: {round(SIM2,2)}\")\n",
    "\n",
    "SMILE1 = GNPS_INFO[CCMSID1]['SMILE']\n",
    "SMILE2 = GNPS_INFO[CCMSID2]['SMILE']\n",
    "print(f'Matched peaks',MP1,MP2,f'Chemical dice {round(cheminfo_tools.dice(SMILE1,SMILE2),2)}')\n",
    "print(CCMSID1,MATRIX1[idx1,idx2], CCMSID2,MATRIX2[idx1,idx2]) # \n",
    "\n",
    "print(f\"{SMILE1}\\n{SMILE2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa9b06-c1d7-4d09-87e1-e926f2e7c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To output matched peaks and scored by scripts\n",
    "spectrum_1 = sus.MsmsSpectrum(identifier='1', \n",
    "                              precursor_mz=PM1, \n",
    "                              precursor_charge=1,\n",
    "                              mz=np.array(SPEC1[:, 0],dtype=np.float64),\n",
    "                              intensity=np.array(SPEC1[:, 1],dtype=np.float64))\n",
    "spectrum_2 = sus.MsmsSpectrum(identifier='2', \n",
    "                              precursor_mz=PM2, \n",
    "                              precursor_charge=1,\n",
    "                              mz=np.array(SPEC2[:, 0],dtype=np.float64),\n",
    "                              intensity=np.array(SPEC2[:, 1],dtype=np.float64)) \n",
    "MCS_RES = peaktools.modified_cosine(spectrum_1,spectrum_2,0.1)\n",
    "NL_RES = peaktools.neutral_loss(spectrum_1,spectrum_2,0.1)\n",
    "MCS_RES,NL_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684d8a5-6537-4aa0-b5cb-9e0faff3a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCS matched peaks and its indices\n",
    "matched_indices = MCS_RES.matched_indices\n",
    "matched_indices_other = MCS_RES.matched_indices_other\n",
    "print(f'Shared peaks of mcs in spectrum1:{spectrum_1.mz[matched_indices]}')\n",
    "print(f'Shared peaks of mcs in spectrum2:{spectrum_2.mz[matched_indices]}')\n",
    "\n",
    "# NL shared peaks and its indices\n",
    "nl_spectrum_1 = peaktools.spec_to_neutral_loss(spectrum_1)\n",
    "nl_spectrum_2 = peaktools.spec_to_neutral_loss(spectrum_2)\n",
    "nl_matched_indices = NL_RES.matched_indices\n",
    "nl_matched_indices_other = NL_RES.matched_indices_other\n",
    "PM1-PM2,nl_spectrum_1.mz[nl_matched_indices],nl_spectrum_2.mz[nl_matched_indices_other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9a646-1ac4-40ed-ab42-72f7405aae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_spectrum = nl_spectrum_2\n",
    "np.column_stack((nl_spectrum.mz,nl_spectrum.intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbaee71-fe5e-4358-aea4-4e6488cae8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matchms v\n",
    "score1 = modified_cosine.pair(SPECTRUM1,SPECTRUM2)\n",
    "score2 = neutral_loss.pair(SPECTRUM1,SPECTRUM2)\n",
    "score1,score2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}