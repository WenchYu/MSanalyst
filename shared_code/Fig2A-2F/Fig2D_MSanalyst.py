
'''
Fig. 2D
Based on the  maximum common structure (MCS) similarity, we divided the annotated pairs into 5 class.
(High Similarity (>70%),Medium Similarity (45%-70%),Low Similarity (35%-45%), Not Similar (<35%), Not compared (under thresholds))

input(generated by Fig2_MSanalystpre.py):
    ./data/MSanalyst/E_**_pp.csv
    ./data/MSanalyst/E_**_sim.csv
    ./data/MSanalyst/IS_**_pp.csv
    ./data/MSanalyst/IS_**_sim.csv
output:
    Data for visualizing in prism
'''
import os
import time

import numpy as np
import pandas as pd
from collections import Counter
from tqdm import tqdm,trange

if __name__ == '__main__':
    t = time.time()

    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
    mps = 5
    for threshold in thresholds:
        isdb_pp_file = f'./data/MSanalyst/IS_MS1match_std_quant.csv_max_pp_{threshold}_{mps}.csv'
        isdb_mq_file = f'./data/MSanalyst/IS_MS1match_std_quant.csv_max_sim_{threshold}_{mps}.csv'
        edb_pp_file = f'./data/MSanalyst/E_MS1match_std_quant.csv_max_pp_{threshold}_{mps}.csv'
        edb_mq_file = f'./data/MSanalyst/E_MS1match_std_quant.csv_max_sim_{threshold}_{mps}.csv'

        isdb_pp_df = pd.read_csv(isdb_pp_file)
        isdb_mq_df = pd.read_csv(isdb_mq_file)
        edb_pp_df = pd.read_csv(edb_pp_file)
        edb_mq_df = pd.read_csv(edb_mq_file)

        columns_to_merge = ['row ID','mcs']
        merged_data = pd.concat(
            [isdb_pp_df[columns_to_merge], isdb_mq_df[columns_to_merge], edb_pp_df[columns_to_merge], edb_mq_df[columns_to_merge]], axis=0)
        # merged_data.to_csv('temp.csv',index = None)  # Save the temp dataframe

        scans = list(Counter(merged_data['row ID']))
        index_to_keep =[]
        for i in scans:
            slice_df = merged_data[merged_data['row ID'] == i]
            index_max = slice_df['mcs'].idxmax()
            if not np.isnan(index_max):
                index_to_keep.append(index_max)
        df_filtered = merged_data.loc[index_to_keep].drop_duplicates(subset='row ID').reset_index(drop=True)

        top1, H, M, L, NS, NC = 0, 0, 0, 0, 0, 0
        for i in range(len(df_filtered)):
            mcs = df_filtered.loc[i, 'mcs']
            if mcs == 1:
                top1 += 1 # Identical annotation
            elif mcs >= 0.7 and mcs < 1:
                H += 1 # High similar annotation
            elif mcs >= 0.45 and mcs < 0.7:
                M += 1 # Medium similar annotation
            elif mcs >= 0.35 and mcs < 0.45:
                L += 1 # Low similar annotation
            else:
                NS += 1 # Non-similar
        NC = 99 - H - M - L - NS - top1 # Unannotated features
        print(f'{NC}\t{NS}\t{L}\t{M}\t{H}\t{top1}') # Data for visualization (figure 2B)


    print(f'Finished in {(time.time() - t) / 60:.2f} min')
